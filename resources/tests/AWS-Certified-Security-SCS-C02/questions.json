[
    {
        "id": "1",
        "question": "A business requires a forensic logging solution for hundreds of Docker-based apps running on Amazon EC2. The solution must analyze logs in real time, provide message replay, and persist logs. Which Amazon Web Offerings (IAM) services should be employed to satisfy these requirements? (Select two.)",
        "options": {
            "1": "Amazon Athena.",
            "2": "Amazon Kinesis.",
            "3": "Amazon SQS.",
            "4": "Amazon Elasticsearch.",
            "5": "Amazon EMR."
        },
        "correct_answers": [
            "options.1",
            "options.2",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "2",
        "question": "A company developed an application by using AWS Lambda, Amazon S3, Amazon Simple Notification Service (Amazon SNS), and Amazon DynamoDB. An external application puts objects into the company's S3 bucket and tags the objects with date and time. A Lambda function periodically pulls data from the company's S3 bucket based on date and time tags and inserts specific values into a DynamoDB table for further processing. The data includes personally identifiable information (Pll). The company must remove data that is older than 30 days from the S3 bucket and the DynamoDB table. Which solution will meet this requirement with the MOST operational efficiency?",
        "options": {
            "1": "Update the Lambda function to add a TTL S3 flag to S3 objects. Create an S3 Lifecycle policy to expire objects that are older than 30 days by using the TTL S3 flag.",
            "2": "Create an S3 Lifecycle policy to expire objects that are older than 30 days. Update the Lambda function to add the TTL attribute in the DynamoDB table. Enable TTL on the DynamoDB table to expire entires that are older than 30 days based on the TTL attribute.",
            "3": "Create an S3 Lifecycle policy to expire objects that are older than 30 days and to add all prefixes to the S3 bucket. Update the Lambda function to delete entries that are older than 30 days.",
            "4": "Create an S3 Lifecycle policy to expire objects that are older than 30 days by using object tags. Update the Lambda function to delete entries that are older than 30 days."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "3",
        "question": "A company is hosting a static website on Amazon S3 The company has configured an Amazon CloudFront distribution to serve the website contents. The company has associated an IAM WAF web ACL with the CloudFront distribution. The web ACL ensures that requests originate from the United States to address compliance restrictions. THE company is worried that the S3 URL might still be accessible directly and that requests can bypass the CloudFront distribution Which combination of steps should the company take to remove direct access to the S3 URL? (Select TWO.)",
        "options": {
            "1": "Select \"Restrict Bucket Access\" in the origin settings of the CloudFront distribution",
            "2": "Create an origin access identity (OAI) for the S3 origin.",
            "3": "Update the S3 bucket policy to allow s3 GetObject with a condition that the IAM Referer key matches the secret value Deny all other.",
            "4": "Configure the S3 bucket poky so that only the origin access identity (OAI) has read permission for objects in the bucket.",
            "5": "Add an origin custom header that has the name Referer to the CloudFront distribution Give the header a secret value."
        },
        "correct_answers": [
            "options.1",
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "4",
        "question": "A company is testing its incident response plan for compromised credentials. The company runs a database on an Amazon EC2 instance and stores the sensitive data-base credentials as a secret in AWS Secrets Manager. The secret has rotation configured with an AWS Lambda function that uses the generic rotation function template. The EC2 instance and the Lambda function are deployed in the same private subnet. The VPC has a Secrets Manager VPC endpoint. A security engineer discovers that the secret cannot rotate. The security engineer determines that the VPC endpoint is working as intended. The Amazon Cloud-Watch logs contain the following error:\"setSecret: Unable to log into database\". Which solution will resolve this error?",
        "options": {
            "1": "Use the AWS Management Console to edit the JSON structure of the secret in Secrets Manager so that the secret automatically conforms with the structure that the database requires.",
            "2": "Ensure that the security group that is attached to the Lambda function al-lows outbound connections to the EC2 instance. Ensure that the security group that is attached to the EC2 instance allows inbound connections from the security group that is attached to the Lambda function.",
            "3": "Use the Secrets Manager list-secrets command in the AWS CLI to list the secret. Identify the database",
            "4": "Add an internet gateway to the VPC. Create a NAT gateway in a public sub-net. Update the VPC route tables so that traffic from the Lambda function and traffic from the EC2 instance can reach the Secrets Manager public endpoint."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "5",
        "question": "A company needs a forensic-logging solution for hundreds of applications running in Docker on Amazon EC2 The solution must perform real-time analytics on the togs must support the replay of messages and must persist the logs. Which IAM services should be used to meet these requirements? (Select TWO)",
        "options": {
            "1": "Amazon Athena.",
            "2": "Amazon Kinesis.",
            "3": "Amazon SQS.",
            "4": "Amazon Elasticsearch.",
            "5": "Amazon EMR."
        },
        "correct_answers": [
            "options.1",
            "options.2",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "6",
        "question": "A company is evaluating the use of AWS Systems Manager Session Manager to gam access to the company's Amazon EC2 instances. However, until the company implements the change, the company must protect the key file for the EC2 instances from read and write operations by any other users. When a security administrator tries to connect to a critical EC2 Linux instance during an emergency, the security administrator receives the following error. \"Error Unprotected private key file \u2013 Permissions for' ssh/my_private_key pern' are too open\". Which command should the security administrator use to modify the private key Me permissions to resolve this error?",
        "options": {
            "1": "chmod 0040 ssh/my_private_key pern.",
            "2": "chmod 0400 ssh/my_private_key pern.",
            "3": "chmod 0004 ssh/my_private_key pern.",
            "4": "chmod 0777 ssh/my_private_key pern."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "7",
        "question": "A company deploys a set of standard IAM roles in AWS accounts. The IAM roles are based on job functions within the company. To balance operational efficiency and security, a security engineer implemented AWS Organizations SCPs to restrict access to critical security services in all company accounts. All of the company's accounts and OUs within AWS Organizations have a default FullAWSAccess SCP that is attached. The security engineer needs to ensure that no one can disable Amazon GuardDuty and AWS Security Hub. The security engineer also must not override other permissions that are granted by IAM policies that are defined in the accounts. Which SCP should the security engineer attach to the root of the organization to meet these requirements? <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question7_1.jpg' alt='Question 7 part 1'> <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question7_2.jpg' alt='Question 7 part 2'> <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question7_3.jpg' alt='Question 7 part 3'> <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question7_4.jpg' alt='Question 7 part 4'>",
        "options": {
            "1": "Option A.",
            "2": "Option B.",
            "3": "Option C.",
            "4": "Option D."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "8",
        "question": "A company is building a data processing application mat uses AWS Lambda functions. The application's Lambda functions need to communicate with an Amazon RDS OB instance that is deployed within a VPC in the same AWS accountWhich solution meets these requirements in the MOST secure way?",
        "options": {
            "1": "Configure the DB instance to allow public access Update the DB instance security group to allow access from the Lambda public address space for the AWS Region.",
            "2": "Deploy the Lambda functions inside the VPC Attach a network ACL to the Lambda subnet Provide outbound rule access to the VPC CIDR range only Update the DB instance security group to allow traffic from 0.0.0.0/0.",
            "3": "Deploy the Lambda functions inside the VPC Attach a security group to the Lambda functions Provide outbound rule access to the VPC CIDR range only Update the DB instance security group to allow traffic from the Lambda security group.",
            "4": "Peer the Lambda default VPC with the VPC that hosts the DB instance to allow direct network access without the need for security groups."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "9",
        "question": "A company has an application that uses an Amazon RDS PostgreSQL database. The company is developing an application feature that will store sensitive information for an individual in the database. During a security review of the environment, the company discovers that the RDS DB instance is not encrypting data at rest. The company needs a solution that will provide encryption at rest for all the existing data and for any new data that is entered for an individual. Which combination of options can the company use to meet these requirements? (Select TWO.)",
        "options": {
            "1": "Create a snapshot of the DB instance. Copy the snapshot to a new snapshot, and enable encryption for the copy process. Use the new snapshot to restore the DB instance.",
            "2": "Modify the configuration of the DB instance by enabling encryption. Create a snapshot of the DB instance. Use the snapshot to restore the DB instance.",
            "3": "Use IAM Key Management Service (IAM KMS) to create a new default IAM managed awards key. Select this key as the encryption key for operations with Amazon RDS.",
            "4": "Use IAM Key Management Service (IAM KMS) to create a new CMK. Select this key as the encryption key for operations with Amazon RDS.",
            "5": "Create a snapshot of the DB instance. Enable encryption on the snapshoVUse the snapshot to restore the DB instance."
        },
        "correct_answers": [
            "options.1",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "10",
        "question": "Which of the following bucket policies will ensure that objects being uploaded to a bucket called \u2018demo' are encrypted. <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question10_1.jpg' alt='Question 10 part 1'> <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question10_2.jpg' alt='Question 10 part 2'> <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question10_3.jpg' alt='Question 10 part 3'> <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question10_4.jpg' alt='Question 10 part 4'>",
        "options": {
            "1": "Option A.",
            "2": "Option B.",
            "3": "Option C.",
            "4": "Option D."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "11",
        "question": "A company uses AWS Organizations to manage a multi-account AWS environment in a single AWS Region. The organization's management account is named management-01. The company has turned on AWS Config in all accounts in the organization. The company has designated an account named security-01 as the delegated administrator for AWS Config. All accounts report the compliance status of each account's rules to the AWS Config delegated administrator account by using an AWS Config aggregator. Each account administrator can configure and manage the account's own AWS Config rules to handle each account's unique compliance requirements. A security engineer needs to implement a solution to automatically deploy a set of 10 AWS Config rules to all existing and future AWS accounts in the organization. The solution must turn on AWS Config automatically during account creation. Which combination of steps will meet these requirements? (Select TWO.)",
        "options": {
            "1": "Create an AWS CloudFormation template that contains the 1 0 required AVVS Config rules. Deploy the template by using CloudFormation StackSets in the security-01 account.",
            "2": "Create a conformance pack that contains the 10 required AWS Config rules. Deploy the conformance pack from the security-01 account.",
            "3": "Create a conformance pack that contains the 10 required AWS Config rules. Deploy the conformance pack from the management-01 account.",
            "4": "Create an AWS CloudFormation template that will activate AWS Config. Deploy the template by using CloudFormation StackSets in the security-01 ac-count.",
            "5": "Create an AWS CloudFormation template that will activate AWS Config. Deploy the template by using CloudFormation StackSets in the management-01 account."
        },
        "correct_answers": [
            "options.2",
            "options.5"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "12",
        "question": "A company has two IAM accounts within IAM Organizations. In Account-1. Amazon EC2 Auto Scaling is launched using a service-linked role. In Account-2. Amazon EBS volumes are encrypted with an IAM KMS key A Security Engineer needs to ensure that the service-linked role can launch instances with these encrypted volumesWhich combination of steps should the Security Engineer take in both accounts? (Select TWO.)",
        "options": {
            "1": "Allow Account-1 to access the KMS key in Account-2 using a key policy",
            "2": "Attach an IAM policy to the service-linked role in Account-1 that allows these actions CreateGrant. DescnbeKey, Encrypt, GenerateDataKey, Decrypt, and ReEncrypt",
            "3": "Create a KMS grant for the service-linked role with these actions CreateGrant, DescnbeKey Encrypt GenerateDataKey Decrypt, and ReEncrypt",
            "4": "Attach an IAM policy to the role attached to the EC2 instances with KMS actions and then allow Account-1 in the KMS key policy.",
            "5": "Attach an IAM policy to the user who is launching EC2 instances and allow the user to access the KMS key policy of Account-2."
        },
        "correct_answers": [
            "options.1",
            "options.3",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "13",
        "question": "Which of the following are valid configurations for using SSL certificates with Amazon CloudFront? (Select THREE)",
        "options": {
            "1": "Default AWS Certificate Manager certificate.",
            "2": "Custom SSL certificate stored in AWS KMS.",
            "3": "Default CloudFront certificate.",
            "4": "Custom SSL certificate stored in AWS Certificate Manager.",
            "5": "Default SSL certificate stored in AWS Secrets Manager.",
            "6": "Custom SSL certificate stored in AWS IAM."
        },
        "correct_answers": [
            "options.1",
            "options.3",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "14",
        "question": "A Security Engineer is troubleshooting an issue with a company's custom logging application. The application logs are written to an Amazon S3 bucket with event notifications enabled to send events lo an Amazon SNS topic. All logs are encrypted at rest using an IAM KMS CMK. The SNS topic is subscribed to an encrypted Amazon SQS queue. The logging application polls the queue for new messages that contain metadata about the S3 object. The application then reads the content of the object from the S3 bucket for indexing. The Logging team reported that Amazon CloudWatch metrics for the number of messages sent or received is showing zero. No tags are being received. What should the Security Engineer do to troubleshoot this issue?",
        "options": {
            "1": "Option A: Add the following statement to the IAM managed CMKs. <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question14_A.jpg' alt='Question 14 option A'>",
            "2": "Option B: Add the following statement to the CMK key policy. <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question14_B.jpg' alt='Question 14 option B'>",
            "3": "Option C: Add the following statement to the CMK key policy. <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question14_C.jpg' alt='Question 14 option C'>",
            "4": "Option D: Add the following statement to the CMK key policy. <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question14_D.jpg' alt='Question 14 option D'>"
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "15",
        "question": "A security engineer needs to implement a write-once-read-many (WORM) model for data that a company will store in Amazon S3 buckets. The company uses the S3 Standard storage class for all of its S3 buckets. The security engineer must ensure that objects cannot be overwritten or deleted by any user, including the AWS account root user. Which solution will meet these requirements?",
        "options": {
            "1": "Create new S3 buckets with S3 Object Lock enabled in compliance mode. Place objects in the S3",
            "2": "Use S3 Glacier Vault Lock to attach a Vault Lock policy to new S3 buckets. Wait 24 hours to complete the Vault Lock process. Place objects in the S3 buckets.",
            "3": "Create new S3 buckets with S3 Object Lock enabled in governance mode. Place objects in the S3 buckets.",
            "4": "Create new S3 buckets with S3 Object Lock enabled in governance mode. Add a legal hold to the S3 buckets. Place objects in the S3 buckets."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "16",
        "question": "A development team is attempting to encrypt and decode a secure string parameter from the IAM Systems Manager Parameter Store using an IAM Key Management Service (IAM KMS) CMK. However, each attempt results in an error message being sent to the development team. Which CMK-related problems possibly account for the error? (Select two.)",
        "options": {
            "1": "The CMK is used in the attempt does not exist.",
            "2": "The CMK is used in the attempt needs to be rotated.",
            "3": "The CMK is used in the attempt is using the CMK\u2122s key ID instead of the CMK ARN.",
            "4": "he CMK is used in the attempt is not enabled.",
            "5": "The CMK is used in the attempt is using an alias."
        },
        "correct_answers": [
            "options.1",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "17",
        "question": "A security engineer logs in to the AWS Lambda console with administrator permissions. The security engineer is trying to view logs in Amazon CloudWatch for a Lambda function that is named my Function. When the security engineer chooses the option in the Lambda console to view logs in CloudWatch, an \u201cerror loading Log Streams\" message appears. The IAM policy for the Lambda function's execution role contains the following:How should the security engineer correct the error? <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question17.jpg' alt='Question 17'>",
        "options": {
            "1": "Move the logs:CreateLogGroup action to the second Allow statement.",
            "2": "Add the logs:PutDestination action to the second Allow statement.",
            "3": "Add the logs:GetLogEvents action to the second Allow statement.",
            "4": "Add the logs:GetLogEvents action to the second Allow statement."
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "18",
        "question": "A company plans to create individual child accounts within an existing organization in IAM Organizations for each of its DevOps teams. IAM CloudTrail has been enabled and configured on all accounts to write audit logs to an Amazon S3 bucket in a centralized IAM account. A security engineer needs to ensure that DevOps team members are unable to modify or disable this configuration. How can the security engineer meet these requirements?",
        "options": {
            "1": "Create an IAM policy that prohibits changes to the specific CloudTrail trail and apply the policy to the IAM account root user.",
            "2": "Create an S3 bucket policy in the specified destination account for the CloudTrail trail that prohibits configuration changes from the IAM account root user in the source account.",
            "3": "Create an SCP that prohibits changes to the specific CloudTrail trail and apply the SCP to the appropriate organizational unit or account in Organizations.",
            "4": "Create an IAM policy that prohibits changes to the specific CloudTrail trail and apply the policy to a"
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "19",
        "question": "A company uses Amazon RDS for MySQL as a database engine for its applications. A recent security audit revealed an RDS instance that is not compliant with company policy for encrypting data at rest. A security engineer at the company needs to ensure that all existing RDS databases are encrypted using server-side encryption and that any future deviations from the policy are detected. Which combination of steps should the security engineer take to accomplish this? (Select TWO.)",
        "options": {
            "1": "Create an IAM Config rule to detect the creation of unencrypted RDS databases. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger on the IAM Config rules compliance state change and use Amazon Simple Notification Service (Amazon SNS) to notify the security operations team.",
            "2": "Use IAM System Manager State Manager to detect RDS database encryption configuration drift. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to track state changes and use Amazon Simple Notification Service (Amazon SNS) to notify the security operations team.",
            "3": "Create a read replica for the existing unencrypted RDS database and enable replica encryption in the process. Once the replica becomes active, promote it into a standalone database instance and terminate the unencrypted database instance.",
            "4": "Take a snapshot of the unencrypted RDS database. Copy the snapshot and enable snapshot encryption in the process. Restore the database instance from the newly created encrypted snapshot. Terminate the unencrypted database instance.",
            "5": "Enable encryption for the identified unencrypted RDS instance by changing the configurations of the existing database."
        },
        "correct_answers": [
            "options.1",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "20",
        "question": "A company has a large fleet of Linux Amazon EC2 instances and Windows EC2 instances that run in private subnets. The company wants all remote administration to be performed as securely as possible in the AWS Cloud. Which solution will meet these requirements?",
        "options": {
            "1": "Do not use SSH-RSA private keys during the launch of new instances. Implement AWS Systems Manager Session Manager.",
            "2": "Generate new SSH-RSA private keys for existing instances. Implement AWS Systems Manager Session Manager.",
            "3": "Do not use SSH-RSA private keys during the launch of new instances. Configure EC2 Instance Connect.",
            "4": "Generate new SSH-RSA private keys for existing instances. Configure EC2 Instance Connect."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "21",
        "question": "A company has an AWS Lambda function that creates image thumbnails from larger images. The Lambda function needs read and write access to an Amazon S3 bucket in the same AWS account. Which solutions will provide the Lambda function this access? (Select TWO.)",
        "options": {
            "1": "Create an IAM user that has only programmatic access. Create a new access key pair. Add environmental variables to the Lambda function with the access key ID and secret access key. Modify the Lambda function to use the environmental variables at run time during communication with Amazon S3.",
            "2": "Generate an Amazon EC2 key pair. Store the private key in AWS Secrets Man-ager. Modify the Lambda function to retrieve the private key from Secrets Manager and to use the private key during communication with Amazon S3.",
            "3": "Create an IAM role for the Lambda function. Attach an IAM policy that al-lows access to the S3 bucket.",
            "4": "Create an IAM role for the Lambda function. Attach a bucket policy to the S3 bucket to allow access. Specify the function's IAM role as the principal.",
            "5": "Create a security group. Attach the security group to the Lambda function. Attach a bucket policy that allows access to the S3 bucket through the security group ID."
        },
        "correct_answers": [
            "options.3",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "22",
        "question": "A security engineer is designing an IAM policy for a script that will use the AWS CLI. The script currently assumes an IAM role that is attached to three AWS managed IAM policies: AmazonEC2FullAccess, AmazonDynamoDBFullAccess, and Ama-zonVPCFull Access. The security engineer needs to construct a least privilege IAM policy that will replace the AWS managed IAM policies that are attached to this role. Which solution will meet these requirements in the MOST operationally efficient way?",
        "options": {
            "1": "In AWS CloudTrail, create a trail for management events. Run the script with the existing AWS managed IAM policies. Use IAM Access Analyzer to generate a new IAM policy that is based on access activity in the trail. Replace the existing AWS managed IAM policies with the generated IAM poli-cy for the role.",
            "2": "Remove the existing AWS managed IAM policies from the role. Attach the IAM Access Analyzer Role Policy Generator to the role. Run the script. Return to IAM Access Analyzer and generate a least privilege IAM policy. Attach the new IAM policy to the role.",
            "3": "Create an account analyzer in IAM Access Analyzer. Create an archive rule that has a filter that checks whether the Principal Arn value matches the ARN of the role. Run the script. Remove the existing AWS managed IAM policies from the role.",
            "4": "In AWS CloudTrail, create a trail for management events. Remove the existing AWS managed IAM policies from the role. Run the script. Find the authorization failure in the trail event that is associated with the script. Create a new IAM policy that includes the action and resource that caused the authorization failure. Repeat the process until the script succeeds. Attach the new IAM policy to the role."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "23",
        "question": "A company that uses AWS Organizations wants to see AWS Security Hub findings for many AWS accounts and AWS Regions. Some of the accounts are in the company's organization, and some accounts are in organizations that the company manages for customers. Although the company can see findings in the Security Hub administrator account for accounts in the company's organization, there are no findings from accounts in other organizations. Which combination of steps should the company take to see findings from accounts that are outside the organization that includes the Security Hub administrator account? (Select TWO.)",
        "options": {
            "1": "Use a designated administration account to automatically set up member accounts.",
            "2": "Create the AWS Service Role ForSecurrty Hub service-linked rote for Security Hub.",
            "3": "Send an administration request from the member accounts.",
            "4": "Enable Security Hub for all member accounts.",
            "5": "Send invitations to accounts that are outside the company's organization from the Security Hub administrator account."
        },
        "correct_answers": [
            "options.1",
            "options.3",
            "options.5"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "24",
        "question": "A company uses identity federation to authenticate users into an identity account (987654321987) where the users assume an IAM role named IdentityRole. The users then assume an IAM role named JobFunctionRole in the target IAM account (123456789123) to perform their job functions. A user is unable to assume the IAM role in the target account. The policy attached to the role in the identity account is. What should be done to enable the user to assume the appropriate role in the target account? <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question24_1.jpg' alt='Question 24 part 1'>",
        "options": {
            "1": "Option A: Update the IAM policy attached to the role in the identity account to be. <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question24_A.png' alt='Question 24 option A'>",
            "2": "Option B: Update the trust policy on the role in the target account to be. <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question24_B.png' alt='Question 24 option B'>",
            "3": "Option C: Update the trust policy on the role in the identity account to be. <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question24_C.png' alt='Question 24 option C'>",
            "4": "Option D: Update the IAM policy attached to the role in the target account to be. <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question24_D.png' alt='Question 24 option D'>"
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "25",
        "question": "A company hosts a web application on an Apache web server. The application runs on Amazon EC2 instances that are in an Auto Scaling group. The company configured the EC2 instances to send the Apache web server logs to an Amazon CloudWatch Logs group that the company has configured to expire after 1 year. Recently, the company discovered in the Apache web server logs that a specific IP address is sending suspicious requests to the web application. A security engineer wants to analyze the past week of Apache web server logs to determine how many requests that the IP address sent and the corresponding URLs that the IP address requested. What should the security engineer do to meet these requirements with the LEAST effort?",
        "options": {
            "1": "Export the CloudWatch Logs group data to Amazon S3. Use Amazon Macie to query the logs for the specific IP address and the requested URLs.",
            "2": "Configure a CloudWatch Logs subscription to stream the log group to an Amazon OpenSearch Service cluster. Use OpenSearch Service to analyze the logs for the specific IP address and the requested URLs.",
            "3": "Use CloudWatch Logs Insights and a custom query syntax to analyze the CloudWatch logs for the specific IP address and the requested URLs.",
            "4": "Export the CloudWatch Logs group data to Amazon S3. Use AWS Glue to crawl the S3 bucket for only the log entries that contain the specific IP ad-dress. Use AWS Glue to view the results."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "26",
        "question": "A company has multiple Amazon S3 buckets encrypted with customer-managed CMKs Due to regulatory requirements the keys must be rotated every year. The company's Security Engineer has enabled automatic key rotation for the CMKs; however the company wants to verity that the rotation has occurred. What should the Security Engineer do to accomplish this?",
        "options": {
            "1": "Filter IAM CloudTrail logs for KeyRotaton events.",
            "2": "Monitor Amazon CloudWatcn Events for any IAM KMS CMK rotation events.",
            "3": "Using the IAM CLI. run the IAM kms gel-key-relation-status operation with the \u2013key-id parameter to check the CMK rotation date.",
            "4": "Use Amazon Athena to query IAM CloudTrail logs saved in an S3 bucket to filter Generate New Key events."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "27",
        "question": "A company has implemented IAM WAF and Amazon CloudFront for an application. The application runs on Amazon EC2 instances that are part of an Auto Scaling group. The Auto Scaling group is behind an Application Load Balancer (ALB). The IAM WAF web ACL uses an IAM Managed Rules rule group and is associated with the CloudFront distribution. CloudFront receives the request from IAM WAF and then uses the ALB as the distribution's origin. During a security review, a security engineer discovers that the infrastructure is susceptible to a large, layer 7 DDoS attack. How can the security engineer improve the security at the edge of the solution to defend against this type of attack?",
        "options": {
            "1": "Configure the CloudFront distribution to use the Lambda@Edge feature. Create an IAM Lambda function that imposes a rate limit on CloudFront viewer requests. Block the request if the rate limit is exceeded.",
            "2": "Configure the IAM WAF web ACL so that the web ACL has more capacity units to process all IAM WAF rules faster.",
            "3": "Configure IAM WAF with a rate-based rule that imposes a rate limit that automatically blocks requests when the rate limit is exceeded.",
            "4": "Configure the CloudFront distribution to use IAM WAF as its origin instead of the ALB."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "28",
        "question": "A company has multiple accounts in the AWS Cloud. Users in the developer account need to have access to specific resources in the production account. What is the MOST secure way to provide this access?",
        "options": {
            "1": "Create one IAM user in the production account. Grant the appropriate permissions to the resources that are needed. Share the password only with the users that need access.",
            "2": "Create cross account access with an IAM role in the developer account. Grant the appropriate permissions to this role. Allow users in the developer account to assume this role to access the production resources.",
            "3": "Create cross-account access with an IAM user account in the production account. Grant the appropriate permissions to this user account. Allow users in the developer account to use this user account to access the production resources.",
            "4": "Create cross-account access with an IAM role in the production account. Grant the appropriate permissions to this role. Allow users in the developer account to assume this role to access the production resources."
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "29",
        "question": "A System Administrator is unable to start an Amazon EC2 instance in the eu-west-1 Region using an IAM role The same System Administrator is able to start an EC2 instance in the eu-west-2 and eu-west-3 Regions. The IAMSystemAdministrator access policy attached to the System Administrator IAM role allows unconditional access to all IAM services and resources within the account. Which configuration caused this issue?",
        "options": {
            "1": "Option A: An SCP is attached to the account with the following permission statement. <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question29_A.jpg' alt='Question 29 option A'>",
            "2": "Option B: A permission boundary policy is attached to the System Administrator role with the following permission statement. <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question29_B.jpg' alt='Question 29 option B'>",
            "3": "Option C: A permission boundary is attached to the System Administrator role with the following permission statement. <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question29_C.jpg' alt='Question 29 option C'>",
            "4": "Option D: An SCP is attached to the account with the following statement. <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question29_D.jpg' alt='Question 29 option D'>"
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "30",
        "question": "Amazon GuardDuty has detected communications to a known command and control endpoint from a company's Amazon EC2 instance. The instance was found to be running a vulnerable version of a common web framework. The company's security operations team wants to quickly identity other compute resources with the specific version of that framework installed. Which approach should the team take to accomplish this task?",
        "options": {
            "1": "Scan all the EC2 instances for noncompliance with IAM Config. Use Amazon Athena to query IAM CloudTrail logs for the framework installation.",
            "2": "Scan all the EC2 instances with the Amazon Inspector Network Reachability rules package to identity instances running a web server with RecognizedPortWithListener findings.",
            "3": "Scan all the EC2 instances with IAM Systems Manager to identify the vulnerable version of the web framework.",
            "4": "Scan an the EC2 instances with IAM Resource Access Manager to identify the vulnerable version of the web framework."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "31",
        "question": "A developer is building a serverless application hosted on AWS that uses Amazon Redshift as a data store The application has separate modules for readwrite and read-only functionality The modules need their own database users for compliance reasons Which combination of steps should a security engineer implement to grant appropriate access? (Select TWO.)",
        "options": {
            "1": "Configure cluster security groups for each application module to control access to database users that are required for read-only and readwrite.",
            "2": "Configure a VPC endpoint for Amazon Redshift Configure an endpoint policy that maps database users to each application module, and allow access to the tables that are required for read-only and read/write.",
            "3": "Configure an 1AM policy for each module Specify the ARN of an Amazon Redshift database user that allows the GetClusterCredentials API call.",
            "4": "Create local database users for each module.",
            "5": "Configure an 1AM policy for each module Specify the ARN of an 1AM user that allows the GetClusterCredentials API call."
        },
        "correct_answers": [
            "options.1",
            "options.3",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "32",
        "question": "A company finds that one of its Amazon EC2 instances suddenly has a high CPU usage. The company does not know whether the EC2 instance is compromised or whether the operating system is performing background cleanup. Which combination of steps should a security engineer take before investigating the issue? (Select THREE.)",
        "options": {
            "1": "Disable termination protection for the EC2 instance if termination protection has not been disabled.",
            "2": "Enable termination protection for the EC2 instance if termination protection has not been enabled.",
            "3": "Take snapshots of the Amazon Elastic Block Store (Amazon EBS) data volumes that are attached to the EC2 instance.",
            "4": "Remove all snapshots of the Amazon Elastic Block Store (Amazon EBS) data volumes that are attached to the EC2 instance.",
            "5": "Capture the EC2 instance metadata, and then tag the EC2 instance as under quarantine.",
            "6": "Immediately remove any entries in the EC2 instance metadata that contain sensitive information."
        },
        "correct_answers": [
            "options.2",
            "options.3",
            "options.5"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "33",
        "question": "A company hosts an application on Amazon EC2 that is subject to specific rules for regulatory compliance. One rule states that traffic to and from the workload must be inspected for network-level attacks. This involves inspecting the whole packet. To comply with this regulatory rule, a security engineer must install intrusion detection software on a c5n.4xlarge EC2 instance. The engineer must then configure the software to monitor traffic to and from the application instances. What should the security engineer do next?",
        "options": {
            "1": "Place the network interface in promiscuous mode to capture the traffic.",
            "2": "Configure VPC Flow Logs to send traffic to the monitoring EC2 instance using a Network Load Balancer.",
            "3": "Configure VPC traffic mirroring to send traffic to the monitoring EC2 instance using a Network Load Balancer.",
            "4": "Use Amazon Inspector to detect network-level attacks and trigger an IAM Lambda function to send the suspicious packets to the EC2 instance."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "34",
        "question": "A company has a relational database workload that runs on Amazon Aurora MySQL. According to new compliance standards the company must rotate all database credentials every 30 days. The company needs a solution that maximizes security and minimizes development effort. Which solution will meet these requirements?",
        "options": {
            "1": "Store the database credentials in AWS Secrets Manager. Configure automatic credential rotation tor every 30 days.",
            "2": "Store the database credentials in AWS Systems Manager Parameter Store. Create an AWS Lambda function to rotate the credentials every 30 days.",
            "3": "Store the database credentials in an environment file or in a configuration file. Modify the credentials every 30 days.",
            "4": "Store the database credentials in an environment file or in a configuration file. Create an AWS Lambda function to rotate the credentials every 30 days."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "35",
        "question": "A company uses AWS Organizations to manage a small number of AWS accounts. However, the company plans to add 1 000 more accounts soon. The company allows only a centralized security team to create IAM roles for all AWS accounts and teams. Application teams submit requests for IAM roles to the security team. The security team has a backlog of IAM role requests and cannot review and provision the IAM roles quickly. The security team must create a process that will allow application teams to provision their own IAM roles. The process must also limit the scope of IAM roles and prevent privilege escalation. Which solution will meet these requirements with the LEAST operational overhead?",
        "options": {
            "1": "Create an IAM group for each application team. Associate policies with each IAM group. Provision IAM users for each application team member. Add the new IAM users to the appropriate IAM group by using role-based access control (RBAC).",
            "2": "Delegate application team leads to provision IAM rotes for each team. Conduct a quarterly review of the IAM rotes the team leads have provisioned. Ensure that the application team leads have the appropriate training to review IAM roles.",
            "3": "Put each AWS account in its own OU. Add an SCP to each OU to grant access to only the AWS services that the teams plan to use. Include conditions tn the AWS account of each team.",
            "4": "Create an SCP and a permissions boundary for IAM roles. Add the SCP to the root OU so that only roles that have the permissions boundary attached can create any new IAM roles."
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "36",
        "question": "A company's security engineer is developing an incident response plan to detect suspicious activity in an AWS account for VPC hosted resources. The security engineer needs to provide visibility for as many AWS Regions as possible. Which combination of steps will meet these requirements MOST cost-effectively? (Select TWO.)",
        "options": {
            "1": "Turn on VPC Flow Logs for all VPCs in the account.",
            "2": "Activate Amazon GuardDuty across all AWS Regions.",
            "3": "Activate Amazon Detective across all AWS Regions.",
            "4": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Create an Amazon EventBridge rule that responds to findings and publishes the findings to the SNS topic.",
            "5": "Create an AWS Lambda function. Create an Amazon EventBridge rule that invokes the Lambda function to publish findings to Amazon Simple Email Ser-vice (Amazon SES)."
        },
        "correct_answers": [
            "options.1",
            "options.2",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "37",
        "question": "A team is using AWS Secrets Manager to store an application database password. Only a limited number of IAM principals within the account can have access to the secret. The principals who require access to the secret change frequently. A security engineer must create a solution that maximizes flexibility and scalability. Which solution will meet these requirements?",
        "options": {
            "1": "Use a role-based approach by creating an IAM role with an inline permissions policy that allows access to the secret. Update the IAM principals in the role trust policy as required.",
            "2": "Deploy a VPC endpoint for Secrets Manager. Create and attach an endpoint policy that specifies the IAM principals that are allowed to access the secret. Update the list of IAM principals as required.",
            "3": "Use a tag-based approach by attaching a resource policy to the secret. Apply tags to the secret and the IAM principals. Use the aws:PrincipalTag and aws:ResourceTag IAM condition keys to control access.",
            "4": "Use a deny-by-default approach by using IAM policies to deny access to the secret explicitly. Attach the policies to an IAM group. Add all IAM principals to the IAM group. Remove principals from the group when they need access. Add the principals to the group again when access is no longer allowed."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "38",
        "question": "A company uses AWS Organizations to run workloads in multiple AWS accounts Currently the individual team members at the company access all Amazon EC2 instances remotely by using SSH or Remote Desktop Protocol (RDP) The company does not have any audit trails and security groups are occasionally open. The company must secure access management and implement a centralized togging solution. Which solution will meet these requirements MOST securely?",
        "options": {
            "1": "Configure trusted access for AWS System Manager in Organizations Configure a bastion host from the management account Replace SSH and RDP by using Systems Manager Session Manager from the management account Configure Session Manager logging to Amazon CloudWatch Logs.",
            "2": "Replace SSH and RDP with AWS Systems Manager Session Manager Install Systems Manager Agent (SSM Agent) on the instances Attach the.",
            "3": "AmazonSSMManagedlnstanceCore role to the instances Configure session data streaming to Amazon CloudWatch Logs Create a separate logging account that has appropriate cross-account permissions to audit the log data.",
            "4": "Install a bastion host in the management account Reconfigure all SSH and RDP to allow access only from the bastion host Install AWS Systems Manager Agent (SSM Agent) on the bastion host Attach the AmazonSSMManagedlnstanceCore role to the bastion host Configure session data streaming to Amazon CloudWatch Logs in a separate logging account to audit log data.",
            "5": "Replace SSH and RDP with AWS Systems Manager State Manager Install Systems Manager Agent (SSM Agent) on the instances Attach the AmazonSSMManagedlnstanceCore role to the instances Configure session data streaming to Amazon CloudTrail Use CloudTrail Insights to analyze the trail data."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "39",
        "question": "A company became aware that one of its access keys was exposed on a code sharing website 11 days ago. A Security Engineer must review all use of the exposed access keys to determine the extent of the exposure. The company enabled IAM CloudTrail m an regions when it opened the account Which of the following will allow (he Security Engineer 10 complete the task?",
        "options": {
            "1": "Filter the event history on the exposed access key in the CloudTrail console Examine the data from the past 11 days.",
            "2": "Use the IAM CLI lo generate an IAM credential report Extract all the data from the past 11 days.",
            "3": "Use Amazon Athena to query the CloudTrail logs from Amazon S3 Retrieve the rows for the exposed access key tor the past 11 days.",
            "4": "Use the Access Advisor tab in the IAM console to view all of the access key activity for the past 11 days."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "40",
        "question": "An application team wants to use IAM Certificate Manager (ACM) to request public certificates to ensure that data is secured in transit. The domains that are being used are not currently hosted on Amazon Route 53 The application team wants to use an IAM managed distribution and caching solution to optimize requests to its systems and provide better points of presence to customers The distribution solution will use a primary domain name that is customized The distribution solution also will use several alternative domain names The certificates must renew automatically over an indefinite period of time Which combination of steps should the application team take to deploy this architecture? (Select THREE.)",
        "options": {
            "1": "Request a certificate (torn ACM in the us-west-2 Region Add the domain names that the certificate will secure.",
            "2": "Send an email message to the domain administrators to request vacation of the domains for ACM.",
            "3": "Request validation of the domains for ACM through DNS Insert CNAME records into each domain's DNS zone.",
            "4": "Create an Application Load Balancer for me caching solution Select the newly requested certificate from ACM to be used for secure connections.",
            "5": "Create an Amazon CloudFront distribution for the caching solution Enter the main CNAME record as the Origin Name Enter the subdomain names or alternate names in the Alternate Domain Names Distribution Settings Select the newly requested certificate from ACM to be used for secure connections.",
            "6": "Request a certificate from ACM in the us-east-1 Region Add the domain names that the certificate wil secure."
        },
        "correct_answers": [
            "options.1",
            "options.3",
            "options.5",
            "options.6"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "41",
        "question": "A company uses Amazon API Gateway to present REST APIs to users. An API developer wants to analyze API access patterns without the need to parse the log files. Which combination of steps will meet these requirements with the LEAST effort? (Select TWO.)",
        "options": {
            "1": "Configure access logging for the required API stage.",
            "2": "Configure an AWS CloudTrail trail destination for API Gateway events. Configure filters on the userldentity, userAgent, and sourcelPAddress fields.",
            "3": "Configure an Amazon S3 destination for API Gateway logs. Run Amazon Athena queries to analyze API access information.",
            "4": "Use Amazon CloudWatch Logs Insights to analyze API access information.",
            "5": "Select the Enable Detailed CloudWatch Metrics option on the required API stage."
        },
        "correct_answers": [
            "options.1",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "42",
        "question": "There are currently multiple applications hosted in a VPC. During monitoring it has been noticed that multiple port scans are coming in from a specific IP Address block. The internal security team has requested that all offending IP Addresses be denied for the next 24 hours. Which of the following is the best method to quickly and temporarily deny access from the specified IP Address's.",
        "options": {
            "1": "Create an AD policy to modify the Windows Firewall settings on all hosts in the VPC to deny access from the IP Address block.",
            "2": "Modify the Network ACLs associated with all public subnets in the VPC to deny access from the IP Address block.",
            "3": "Add a rule to all of the VPC Security Groups to deny access from the IP Address block.",
            "4": "Modify the Windows Firewall settings on all AMI'S that your organization uses in that VPC to deny access from the IP address block."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "43",
        "question": "A company needs to store multiple years of financial records. The company wants to use Amazon S3 to store copies of these documents. The company must implement a solution to prevent the documents from being edited, replaced, or deleted for 7 years after the documents are stored in Amazon S3. The solution must also encrypt the documents at rest. A security engineer creates a new S3 bucket to store the documents. What should the security engineer do next to meet these requirements?",
        "options": {
            "1": "Configure S3 server-side encryption. Create an S3 bucket policy that has an explicit deny rule for all users for s3:DeleteObject and s3:PutObject API calls. Configure S3 Object Lock to use governance mode with a retention period of 7 years.",
            "2": "Configure S3 server-side encryption. Configure S3 Versioning on the S3 bucket. Configure S3 Object Lock to use compliance mode with a retention period of 7 years.",
            "3": "Configure S3 Versioning. Configure S3 Intelligent-Tiering on the S3 bucket to move the documents to S3 Glacier Deep Archive storage. Use S3 server-side encryption immediately. Expire the objects after 7 years.",
            "4": "Set up S3 Event Notifications and use S3 server-side encryption. Configure S3 Event Notifications to target an AWS Lambda function that will review any S3 API call to the S3 bucket and deny the s3:DeleteObject and s3:PutObject API calls. Remove the S3 event notification after 7 years."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "44",
        "question": "There is a requirement for a company to transfer large amounts of data between IAM and an on-premise location. There is an additional requirement for low latency and high consistency traffic to IAM. Given these requirements how would you design a hybrid architecture? Choose the correct answer from the options below",
        "options": {
            "1": "Provision a Direct Connect connection to an IAM region using a Direct Connect partner.",
            "2": "Create a VPN tunnel for private connectivity, which increases network consistency and reduces latency.",
            "3": "Create an IPsec tunnel for private connectivity, which increases network consistency and reduces latency.",
            "4": "Create a VPC peering connection between IAM and the Customer gateway."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "45",
        "question": "A company uses a third-party identity provider and SAML-based SSO for its AWS accounts. After the third-party identity provider renewed an expired signing certificate, users saw the following message when trying to log in: Error: Response Signature Invalid (Service: AWSSecurityTokenService; Status Code: 400; Error Code:InvalidldentityToken). A security engineer needs to provide a solution that corrects the error and minimizes operational overhead. Which solution meets these requirements? <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question45.png' alt='Question 45'>",
        "options": {
            "1": "Upload the third-party signing certificate's new private key to the AWS identity provider entity defined in AWS Identity and Access Management (IAM) by using the AWS Management Console.",
            "2": "Sign the identity provider's metadata file with the new public key. Upload the signature to the AWS identity provider entity defined in AWS Identity and Access Management (IAM) by using the AWS CU.",
            "3": "Download the updated SAML metadata file from the identity service provider. Update the file in the AWS identity provider entity defined in AWS Identity and Access Management (IAM) by using the AWS CLI.",
            "4": "Configure the AWS identity provider entity defined in AWS Identity and Access Management (IAM) to synchronously fetch the new public key by using the AWS Management Console."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "46",
        "question": "An AWS account that is used for development projects has a VPC that contains two subnets. The first subnet is named public-subnet-1 and has the CIDR block 192.168.1.0/24 assigned. The other subnet is named private-subnet-2 and has the CIDR block 192.168.2.0/24 assigned. Each subnet contains Amazon EC2 instances. Each subnet is currently using the VPC's default network ACL. The security groups that the EC2 instances in these subnets use have rules that allow traffic between each instance where required. Currently, all network traffic flow is working as expected between the EC2 instances that are using these subnets. A security engineer creates a new network ACL that is named subnet-2-NACL with default entries. The security engineer immediately configures private-subnet-2 to use the new network ACL and makes no other changes to the infrastructure. The security engineer starts to receive reports that the EC2 instances in public-subnet-1 and public-subnet-2 cannot communicate with each other. Which combination of steps should the security engineer take to allow the EC2 instances that are running in these two subnets to communicate again? (Select TWO.)",
        "options": {
            "1": "Add an outbound allow rule for 192.168.2.0/24 in the VPC's default network ACL.",
            "2": "Add an inbound allow rule for 192.168.2.0/24 in the VPC's default network ACL.",
            "3": "Add an outbound allow rule for 192.168.2.0/24 in subnet-2-NACL.",
            "4": "Add an inbound allow rule for 192.168.1.0/24 in subnet-2-NACL.",
            "5": "Add an outbound allow rule for 192.168.1.0/24 in subnet-2-NACL."
        },
        "correct_answers": [
            "options.1",
            "options.3",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "47",
        "question": "Within a VPC, a corporation runs an Amazon RDS Multi-AZ DB instance. The database instance is connected to the internet through a NAT gateway via two subnets. Additionally, the organization has application servers that are hosted on Amazon EC2 instances and use the RDS database. These EC2 instances have been deployed onto two more private subnets inside the same VPC. These EC2 instances connect to the internet through a default route via the same NAT gateway. Each VPC subnet has its own route table. The organization implemented a new security requirement after a recent security examination. Never allow the database instance to connect to the internet. A security engineer must perform this update promptly without interfering with the network traffic of the application servers. How will the security engineer be able to comply with these requirements?",
        "options": {
            "1": "Remove the existing NAT gateway. Create a new NAT gateway that only the application server subnets can use.",
            "2": "Configure the DB instance\u2122s inbound network ACL to deny traffic from the security group ID of the NAT gateway.",
            "3": "Modify the route tables of the DB instance subnets to remove the default route to the NAT gateway.",
            "4": "Configure the route table of the NAT gateway to deny connections to the DB instance subnets."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "48",
        "question": "An audit determined that a company's Amazon EC2 instance security group violated company policy by allowing unrestricted incoming SSH traffic. A security engineer must implement a near-real-time monitoring and alerting solution that will notify administrators of such violations. Which solution meets these requirements with the MOST operational efficiency?",
        "options": {
            "1": "Create a recurring Amazon Inspector assessment run that runs every day and uses the Network Reachability package. Create an Amazon CloudWatch rule that invokes an IAM Lambda function when an assessment run starts. Configure the Lambda function to retrieve and evaluate the assessment run report when it completes. Configure the Lambda function also to publish an Amazon Simple Notification Service (Amazon SNS) notification if there are any violations for unrestricted incoming SSH traffic.",
            "2": "Use the restricted-ssh IAM Config managed rule that is invoked by security group configuration changes that are not compliant. Use the IAM Config remediation feature to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic.",
            "3": "Configure VPC Flow Logs for the VPC. and specify an Amazon CloudWatch Logs group. Subscribe the CloudWatch Logs group to an IAM Lambda function that parses new log entries, detects successful connections on port 22, and publishes a notification through Amazon Simple Notification Service (Amazon SNS).",
            "4": "Create a recurring Amazon Inspector assessment run that runs every day and uses the Security Best Practices package. Create an Amazon CloudWatch rule that invokes an IAM Lambda function when an assessment run starts. Configure the Lambda function to retrieve and evaluate the assessment run report when it completes. Configure the Lambda function also to publish an Amazon Simple Notification Service (Amazon SNS) notification if there are any violations for unrestricted incoming SSH traffic."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "49",
        "question": "A company is using Amazon Elastic Container Service (Amazon ECS) to deploy an application that deals with sensitive data During a recent security audit, the company identified a security issue in which Amazon RDS credentials were stored with the application code In the company's source code repository A security engineer needs to develop a solution to ensure that database credentials are stored securely and rotated periodically. The credentials should be accessible to the application only The engineer also needs to prevent database administrators from sharing database credentials as plaintext with other teammates. The solution must also minimize administrate overhead Which solution meets these requirements?",
        "options": {
            "1": "se the IAM Systems Manager Parameter Store to generate database credentials. Use an IAM profile for ECS tasks to restrict access to database credentials to specific containers only.",
            "2": "Use IAM Secrets Manager to store database credentials. Use an IAM inline policy for ECS tasks to restrict access to database credentials to specific containers only.",
            "3": "Use the IAM Systems Manager Parameter Store to store database credentials. Use IAM roles for ECS tasks to restrict access to database credentials lo specific containers only",
            "4": "Use IAM Secrets Manager to store database credentials. Use IAM roles for ECS tasks to restrict access to database credentials to specific containers only."
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "50",
        "question": "A company discovers a billing anomaly in its AWS account. A security consultant investigates the anomaly and discovers that an employee who left the company 30 days ago still has access to the account. The company has not monitored account activity in the past. The security consultant needs to determine which resources have been deployed or reconfigured by the employee as quickly as possible. Which solution will meet these requirements?",
        "options": {
            "1": "In AWS Cost Explorer, filter chart data to display results from the past 30 days. Export the results to a data table. Group the data table by re-source.",
            "2": "Use AWS Cost Anomaly Detection to create a cost monitor. Access the detection history. Set the time frame to Last 30 days. In the search area, choose the service category.",
            "3": "In AWS CloudTrail, filter the event history to display results from the past 30 days. Create an Amazon Athena table that contains the data. Partition the table by event source.",
            "4": "Use AWS Audit Manager to create an assessment for the past 30 days. Apply a usage-based framework to the assessment. Configure the assessment to assess by resource."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "51",
        "question": "A company wants to monitor the deletion of AWS Key Management Service (AWS KMS) customer managed keys. A security engineer needs to create an alarm that will notify the company before a KMS key is deleted. The security engineer has configured the integration of AWS CloudTrail with Amazon CloudWatch. What should the security engineer do next to meet these requirements?",
        "options": {
            "1": "Specify the deletion time of the key material during KMS key creation. Create a custom AWS Config rule to assess the key's scheduled deletion. Configure the rule to trigger upon a configuration change. Send a message to an Amazon Simple Notification Service (Amazon SNS) topic if the key is scheduled for deletion.",
            "2": "Create an Amazon EventBridge rule to detect KMS API calls of DeleteAlias. Create an AWS Lambda function to send an Amazon Simple Notification Service (Amazon SNS) message to the company. Add the Lambda function as the target of the EventBridge rule.",
            "3": "Create an Amazon EventBridge rule to detect KMS API calls of DisableKey and ScheduleKeyDeletion. Create an AWS Lambda function to send an Amazon Simple Notification Service (Amazon SNS) message to the company. Add the Lambda function as the target of the EventBridge rule.",
            "4": "Create an Amazon Simple Notification Service (Amazon SNS) policy to detect KMS API calls of RevokeGrant and ScheduleKeyDeletion. Create an AWS Lambda function to generate the alarm and send the notification to the company. Add the Lambda function as the target of the SNS policy."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "52",
        "question": "A company accidentally deleted the private key for an Amazon Elastic Block Store (Amazon EBS)-backed Amazon EC2 instance. A security engineer needs to regain access to the instance. Which combination of steps will meet this requirement? (Choose two.)",
        "options": {
            "1": "Stop the instance. Detach the root volume. Generate a new key pair.",
            "2": "Keep the instance running. Detach the root volume. Generate a new key pair.",
            "3": "When the volume is detached from the original instance, attach the volume to another instance as a data volume. Modify the authorized_keys file with a new public key. Move the volume back to the original instance. Start the instance.",
            "4": "When the volume is detached from the original instance, attach the volume to another instance as a data volume. Modify the authorized_keys file with a new private key. Move the volume back to the original instance. Start the instance.",
            "5": "When the volume is detached from the original instance, attach the volume to another instance as a data volume. Modify the authorized_keys file with a new public key. Move the volume back to the original instance that is running."
        },
        "correct_answers": [
            "options.1",
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "53",
        "question": "A company deployed Amazon GuardDuty In the us-east-1 Region. The company wants all DNS logs that relate to the company's Amazon EC2 instances to be inspected. What should a security engineer do to ensure that the EC2 instances are logged?",
        "options": {
            "1": "Use IPv6 addresses that are configured for hostnames.",
            "2": "Configure external DNS resolvers as internal resolvers that are visible only to IAM.",
            "3": "Use IAM DNS resolvers for all EC2 instances.",
            "4": "Configure a third-party DNS resolver with logging for all EC2 instances."
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "54",
        "question": "An ecommerce website was down for 1 hour following a DDoS attack Users were unable to connect to the website during the attack period. The ecommerce company's security team is worried about future potential attacks and wants to prepare for such events The company needs to minimize downtime in its response to similar attacks in the future. Which steps would help achieve this9 (Select TWO)",
        "options": {
            "1": "Enable Amazon GuardDuty to automatically monitor for malicious activity and block unauthorized access.",
            "2": "Subscribe to IAM Shield Advanced and reach out to IAM Support in the event of an attack.",
            "3": "Use VPC Flow Logs to monitor network: traffic and an IAM Lambda function to automatically block an attacker's IP using security groups.",
            "4": "Set up an Amazon CloudWatch Events rule to monitor the IAM CloudTrail events in real time use IAM Config rules to audit the configuration, and use IAM Systems Manager for remediation.",
            "5": "Use IAM WAF to create rules to respond to such attacks."
        },
        "correct_answers": [
            "options.1",
            "options.2",
            "options.5"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "55",
        "question": "A security engineer receives an IAM abuse email message. According to the message, an Amazon EC2 instance that is running in the security engineer's IAM account is sending phishing email messages.  The EC2 instance is part of an application that is deployed in production. The application runs on many EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple subnets and multiple Availability Zones. The instances normally communicate only over the HTTP. HTTPS, and MySQL protocols. Upon investigation, the security engineer discovers that email messages are being sent over port 587. All other traffic is normal. The security engineer must create a solution that contains the compromised EC2 instance, preserves forensic evidence for analysis, and minimizes application downtime. Which combination of steps must the security engineer take to meet these requirements? (Select THREE.)",
        "options": {
            "1": "Add an outbound rule to the security group that is attached to the compromised EC2 instance to deny traffic to 0.0.0.0/0 and port 587.",
            "2": "Add an outbound rule to the network ACL for the subnet that contains the compromised EC2 instance to deny traffic to 0.0.0.0/0 and port 587.",
            "3": "Gather volatile memory from the compromised EC2 instance. Suspend the compromised EC2 instance from the Auto Scaling group. Then take a snapshot of the compromised EC2 instance.",
            "4": "Take a snapshot of the compromised EC2 instance. Suspend the compromised EC2 instance from the Auto Scaling group. Then gather volatile memory from the compromised EC2 instance.",
            "5": "Move the compromised EC2 instance to an isolated subnet that has a network ACL that has no inbound rules or outbound rules.",
            "6": "Replace the existing security group that is attached to the compromised EC2 instance with a new security group that has no inbound rules or outbound rules."
        },
        "correct_answers": [
            "options.1",
            "options.3",
            "options.5"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "56",
        "question": "You need to create a policy and apply it for just an individual user. How could you accomplish this in the right way?",
        "options": {
            "1": "Add an IAM managed policy for the user.",
            "2": "Add a service policy for the user.",
            "3": "Add an IAM role for the user.",
            "4": "Add an inline policy for the user."
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "57",
        "question": "Company A has an AWS account that is named Account A. Company A recently acquired Company B, which has an AWS account that is named Account B. Company B stores its files in an Amazon S3 bucket. The administrators need to give a user from Account A full access to the S3 bucket in Account B. After the administrators adjust the IAM permissions for the user in Account A to access the S3 bucket in Account B, the user still cannot access any files in the S3 bucket. Which solution will resolve this issue?",
        "options": {
            "1": "In Account B, create a bucket ACL to allow the user from Account A to access the S3 bucket in Account B.",
            "2": "In Account B, create an object ACL to allow the user from Account A to access all the objects in the S3 bucket in Account B.",
            "3": "In Account B, create a bucket policy to allow the user from Account A to access the S3 bucket in Account B.",
            "4": "In Account B, create a user policy to allow the user from Account A to access the S3 bucket in Account B."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "58",
        "question": "A company has a web-based application using Amazon CloudFront and running on Amazon Elastic Container Service (Amazon ECS) behind an Application Load Balancer (ALB). The ALB is terminating TLS and balancing load across ECS service tasks A security engineer needs to design a solution to ensure that application content is accessible only through CloudFront and that I is never accessible directly. How should the security engineer build the MOST secure solution?",
        "options": {
            "1": "Add an origin custom header Set the viewer protocol policy to HTTP and HTTPS Set the origin protocol pokey to HTTPS only Update the application to validate the CloudFront custom header.",
            "2": "Add an origin custom header Set the viewer protocol policy to HTTPS only Set the origin protocol policy to match viewer Update the application to validate the CloudFront custom header.",
            "3": "Add an origin custom header Set the viewer protocol policy to redirect HTTP to HTTPS Set the origin protocol policy to HTTP only Update the application to validate the CloudFront custom header.",
            "4": "Add an origin custom header Set the viewer protocol policy to redirect HTTP to HTTPS. Set the origin protocol policy to HTTPS only Update the application to validate the CloudFront custom header."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "59",
        "question": "A company is using IAM Secrets Manager to store secrets for its production Amazon RDS database. The Security Officer has asked that secrets be rotated every 3 months. Which solution would allow the company to securely rotate the secrets? (Select TWO.)",
        "options": {
            "1": "Place the RDS instance in a public subnet and an IAM Lambda function outside the VPC. Schedule the Lambda function to run every 3 months to rotate the secrets.",
            "2": "Place the RDS instance in a private subnet and an IAM Lambda function inside the VPC in the private subnet. Configure the private subnet to use a NAT gateway. Schedule the Lambda function to run every 3 months to rotate the secrets.",
            "3": "Place the RDS instance in a private subnet and an IAM Lambda function outside the VPC. Configure the private subnet to use an internet gateway. Schedule the Lambda function to run every 3 months lo rotate the secrets.",
            "4": "Place the RDS instance in a private subnet and an IAM Lambda function inside the VPC in the private subnet. Schedule the Lambda function to run quarterly to rotate the secrets.",
            "5": "Place the RDS instance in a private subnet and an IAM Lambda function inside the VPC in the private subnet. Configure a Secrets Manager interface endpoint. Schedule the Lambda function to run every 3 months to rotate the secrets."
        },
        "correct_answers": [
            "options.2",
            "options.5"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "60",
        "question": "You work at a company that makes use of IAM resources. One of the key security policies is to ensure that all data i encrypted both at rest and in transit. Which of the following is one of the right ways to implement this.",
        "options": {
            "1": "Use S3 SSE and use SSL for data in transit",
            "2": "SSL termination on the ELB",
            "3": "Enabling Proxy Protocol",
            "4": "Enabling sticky sessions on your load balancer"
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "61",
        "question": "A security engineer configures Amazon S3 Cross-Region Replication (CRR) for all objects that are in an S3 bucket in the us-east-1. Region Some objects in this S3 bucket use server-side encryption with AWS KMS keys (SSE-KMS) for encryption at test. The security engineer creates a destination S3 bucket in the us-west-2 Region. The destination S3 bucket is in the same AWS account as the source S3 bucket. The security engineer also creates a customer managed key in us-west-2 to encrypt objects at rest in the destination S3 bucket. The replication configuration is set to use the key in us-west-2 to encrypt objects in the destination S3 bucket. The security engineer has provided the S3 replication configuration with an IAM role to perform the replication in Amazon S3. After a day, the security engineer notices that no encrypted objects from the source S3 bucket are replicated to the destination S3 bucket. However, all the unencrypted objects are replicated. Which combination of steps should the security engineer take to remediate this issue? (Select THREE.)",
        "options": {
            "1": "Change the replication configuration to use the key in us-east-1 to encrypt the objects that are in the destination S3 bucket.",
            "2": "Grant the IAM role the kms. Encrypt permission for the key in us-east-1 that encrypts source objects.",
            "3": "Grant the IAM role the s3 GetObjectVersionForReplication permission for objects that are in the source S3 bucket.",
            "4": "Grant the IAM role the kms. Decrypt permission for the key in us-east-1 that encrypts source objects.",
            "5": "Change the key policy of the key in us-east-1 to grant the kms. Decrypt permission to the security engineer's IAM account.",
            "6": "Grant the IAM role the kms Encrypt permission for the key in us-west-2 that encrypts objects that are in the destination S3 bucket."
        },
        "correct_answers": [
            "options.3",
            "options.4",
            "options.6"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "62",
        "question": "A company uses an Amazon S3 bucket to store reports Management has mandated that all new objects stored in this bucket must be encrypted at rest using server-side encryption with a client-specified IAM Key Management Service (IAM KMS) CMK owned by the same account as the S3 bucket. The IAM account number is 111122223333, and the bucket name Is report bucket. The company's security specialist must write the S3 bucket policy to ensure the mandate can be Implemented Which statement should the security specialist include in the policy? <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question62_1.jpg' alt='Question 62 part 1'> <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question62_2.jpg' alt='Question 62 part 2'> <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question62_3.jpg' alt='Question 62 part 3'> <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question62_4.jpg' alt='Question 62 part 4'>",
        "options": {
            "1": "Option A.",
            "2": "Option B.",
            "3": "Option C.",
            "4": "Option D."
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "63",
        "question": "A developer 15 building a serverless application hosted on IAM that uses Amazon Redshift in a data store. The application has separate modules for read/write and read-only functionality. The modules need their own database users tor compliance reasons. Which combination of steps should a security engineer implement to grant appropriate access' (Select TWO)",
        "options": {
            "1": "Configure cluster security groups for each application module to control access to database users that are required for read-only and read/write.",
            "2": "Configure a VPC endpoint for Amazon Redshift Configure an endpoint policy that maps database users to each application module, and allow access to the tables that are required for read-only and read/write.",
            "3": "Configure an IAM poky for each module Specify the ARN of an Amazon Redshift database user that allows the GetClusterCredentials API call.",
            "4": "Create focal database users for each module.",
            "5": "Configure an IAM policy for each module Specify the ARN of an IAM user that allows the GetClusterCredentials API call."
        },
        "correct_answers": [
            "options.3",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "64",
        "question": "Your company uses AWS to host its resources. They have the following requirements: 1. Record all API calls and Transitions. 2. Help in understanding what resources are there in the account. 3. Facility to allow auditing credentials and logins Which services would suffice the above requirements. Please select:",
        "options": {
            "1": "1. IAM Inspector. 2. CloudTrail. 3. IAM Credential Reports.",
            "2": "1. CloudTrail. 2. IAM Credential Reports. 3. IAM SNS.",
            "3": "1. CloudTrail. 2. IAM Config. 3. IAM Credential Reports.",
            "4": "1. IAM SQS. 2. IAM Credential Reports. 3. CloudTrail."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "65",
        "question": "A company is designing a multi-account structure for its development teams. The company is using AWS Organizations and AWS Single Sign-On (AWS SSO). The company must implement a solution so that the development teams can use only specific AWS Regions and so that each AWS account allows access to only specific AWS services. Which solution will meet these requirements with the LEAST operational overhead?",
        "options": {
            "1": "Use AWS SSO to set up service-linked roles with IAM policy statements that include the Condition, Resource, and NotAction elements to allow access to only the Regions and services that are needed.",
            "2": "Deactivate AWS Security Token Service (AWS STS) in Regions that the developers are not allowed to use.",
            "3": "Create SCPs that include the Condition, Resource, and NotAction elements to allow access to only the Regions and services that are needed.",
            "4": "For each AWS account, create tailored identity-based policies for AWS SSO. Use statements that include the Condition, Resource, and NotAction elements to allow access to only the Regions and services that are needed."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "66",
        "question": "A company has deployed Amazon GuardDuty and now wants to implement automation for potential threats. The company has decided to start with RDP brute force attacks that come from Amazon EC2 instances in the company's AWS environment. A security engineer needs to implement a solution that blocks the detected communication from a suspicious instance until investigation and potential remediation can occur. Which solution will meet these requirements?",
        "options": {
            "1": "Configure GuardDuty to send the event to an Amazon Kinesis data stream. Process the eventwith an Amazon Kinesis Data Analytics for Apache Flink application that sends a notification to the company through Amazon Simple Notification Service (Amazon SNS). Add rules to the network ACL to block traffic to and from the suspicious instance.",
            "2": "Configure GuardDuty to send the event to Amazon EventBridge (Amazon CloudWatch Events). Deploy an AWS WAF web ACL. Process the event with an AWS Lambda function that sends a notification to the company through Amazon Simple Notification Service (Amazon SNS) and adds a web ACL rule to block traffic to and from the suspicious instance.",
            "3": "Enable AWS Security Hub to ingest GuardDuty findings and send the event to Amazon EventBridge (Amazon CloudWatch Events). Deploy AWS Network Firewall. Process the event with an AWS Lambda function that adds a rule to a Network Firewall firewall policy to block traffic to and from the suspicious instance.",
            "4": "Enable AWS Security Hub to ingest GuardDuty findings. Configure an Amazon Kinesis data stream as an event destination for Security Hub. Process the event with an AWS Lambda function that replaces the security group of the suspicious instance with a security group that does not allow any connections."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "67",
        "question": "A company uses an external identity provider to allow federation into different IAM accounts. A security engineer for the company needs to identify the federated user that terminated a production Amazon EC2 instance a week ago. What is the FASTEST way for the security engineer to identify the federated user?",
        "options": {
            "1": "Review the IAM CloudTrail event history logs in an Amazon S3 bucket and look for the Terminatelnstances event to identify the federated user from the role session name.",
            "2": "Filter the IAM CloudTrail event history for the Terminatelnstances event and identify the assumed IAM role. Review the AssumeRoleWithSAML event call in CloudTrail to identify the corresponding username.",
            "3": "Search the IAM CloudTrail logs for the Terminatelnstances event and note the event time. Review the IAM Access Advisor tab for all federated roles. The last accessed time should match the time when the instance was terminated.",
            "4": "Use Amazon Athena to run a SQL query on the IAM CloudTrail logs stored in an Amazon S3 bucket and filter on the Terminatelnstances event. Identify the corresponding role and run another query to filter the AssumeRoleWithWebldentity event for the user name."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "68",
        "question": "A company Is planning to use Amazon Elastic File System (Amazon EFS) with its on-premises servers. The company has an existing IAM Direct Connect connection established between its on-premises data center and an IAM Region Security policy states that the company's on-premises firewall should only have specific IP addresses added to the allow list and not a CIDR range. The company also wants to restrict access so that only certain data center-based servers have access to Amazon EFS How should a security engineer implement this solution\u201d",
        "options": {
            "1": "Add the file-system-id efs IAM-region amazonIAM com URL to the allow list for the data center firewall Install the IAM CLI on the data center-based servers to mount the EFS file system in the EFS security group add the data center IP range to the allow list Mount the EFS using the EFS file system name.",
            "2": "Assign an Elastic IP address to Amazon EFS and add the Elastic IP address to the allow list for the data center firewall Install the IAM CLI on the data center-based servers to mount the EFS file system In the EFS security group, add the IP addresses of the data center servers to the allow list Mount the EFS using the Elastic IP address.",
            "3": "Add the EFS file system mount target IP addresses to the allow list for the data center firewall In the EFS security group, add the data center server IP addresses to the allow list Use the Linux terminal to mount the EFS file system using the IP address of one of the mount targets.",
            "4": "Assign a static range of IP addresses for the EFS file system by contacting IAM Support In the EFS security group add the data center server IP addresses to the allow list Use the Linux terminal to mount the EFS file system using one of the static IP addresses."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "69",
        "question": "A website currently runs on Amazon EC2, wan mostly statics content on the site. Recently the site was subjected to a DDoS attack a security engineer was (asked was redesigning the edge security to help Mitigate this risk in the future. What are some ways the engineer could achieve this (Select THREE)?",
        "options": {
            "1": "Use IAM X-Ray to inspect the trafc going to the EC2 instances.",
            "2": "Move the static content to Amazon S3, and front this with an Amazon Cloud Front distribution.",
            "3": "Change the security group conguration to block the source of the attack trafc",
            "4": "Use IAM WAF security rules to inspect the inbound trafc.",
            "5": "Use Amazon Inspector assessment templates to inspect the inbound traffic.",
            "6": "Use Amazon Route 53 to distribute trafc."
        },
        "correct_answers": [
            "options.2",
            "options.4",
            "options.6"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "70",
        "question": "A company needs to use HTTPS when connecting to its web applications to meet compliance requirements. These web applications run in Amazon VPC on Amazon EC2 instances behind an Application Load Balancer (ALB). A security engineer wants to ensure that the load balancer win only accept connections over port 443. even if the ALB is mistakenly configured with an HTTP listener Which configuration steps should the security engineer take to accomplish this task?",
        "options": {
            "1": "Create a security group with a rule that denies Inbound connections from 0.0.0 0/0 on port 00. Attach this security group to the ALB to overwrite more permissive rules from the ALB's default security group.",
            "2": "Create a network ACL that denies inbound connections from 0 0.0.0/0 on port 80 Associate the network ACL with the VPC s internet gateway.",
            "3": "Create a network ACL that allows outbound connections to the VPC IP range on port 443 only. Associate the network ACL with the VPC's internet gateway.",
            "4": "Create a security group with a single inbound rule that allows connections from 0.0.0 0/0 on port 443. Ensure this security group is the only one associated with the ALB."
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "71",
        "question": "Example.com is hosted on Amazon EC2 instances behind an Application Load Balancer (ALB). Third-party host intrusion detection system (HIDS) agents that capture the traffic of the EC2 instance are running on each host. The company must ensure they are using privacy enhancing technologies for users, without losing the assurance the third-party solution offers. What is the MOST secure way to meet these requirements?",
        "options": {
            "1": "Enable TLS pass through on the ALB, and handle decryption at the server using Elliptic Curve Diffie-Hellman (ECDHE) cipher suites.",
            "2": "Create a listener on the ALB that uses encrypted connections with Elliptic Curve Diffie-Hellman (ECDHE) cipher suites, and pass the traffic in the clear to the server.",
            "3": "Create a listener on the ALB that uses encrypted connections with Elliptic Curve Diffie-Hellman (ECDHE) cipher suites, and use encrypted connections to the servers that do not enable Perfect Forward Secrecy (PFS).",
            "4": "Create a listener on the ALB that does not enable Perfect Forward Secrecy (PFS) cipher suites, and use encrypted connections to the servers using Elliptic Curve Diffie-Hellman (ECDHE) cipher suites."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "72",
        "question": "A company has an AWS Key Management Service (AWS KMS) customer managed key with imported key material Company policy requires all encryption keys to be rotated every year What should a security engineer do to meet this requirement for this customer managed key?",
        "options": {
            "1": "Enable automatic key rotation annually for the existing customer managed key.",
            "2": "Use the AWS CLI to create an AWS Lambda function to rotate the existing customer managed key annually.",
            "3": "Import new key material to the existing customer managed key Manually rotate the key.",
            "4": "Create a new customer managed key Import new key material to the new key Point the key alias to the new key."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "73",
        "question": "A company's on-premises networks are connected to VPCs using an IAM Direct Connect gateway. The company's on-premises application needs to stream data using an existing Amazon Kinesis Data Firehose delivery stream. The company's security policy requires that data be encrypted in transit using a private network. How should the company meet these requirements?",
        "options": {
            "1": "Create a VPC endpoint tor Kinesis Data Firehose. Configure the application to connect to the VPC endpoint.",
            "2": "Configure an IAM policy to restrict access to Kinesis Data Firehose using a source IP condition. Configure the application to connect to the existing Firehose delivery stream.",
            "3": "Create a new TLS certificate in IAM Certificate Manager (ACM). Create a public-facing Network Load Balancer (NLB) and select the newly created TLS certificate. Configure the NLB to forward all traffic to Kinesis Data Firehose. Configure the application to connect to the NLB.",
            "4": "Peer the on-premises network with the Kinesis Data Firehose VPC using Direct Connect. Configure the application to connect to the existing Firehose delivery stream."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "74",
        "question": "A security team is using Amazon EC2 Image Builder to build a hardened AMI with forensic capabilities. An AWS Key Management Service (AWS KMS) key will encrypt the forensic AMI EC2 Image Builder successfully installs the required patches and packages in the security team's AWS account. The security team uses a federated IAM role m the same AWS account to sign in to the AWS Management Console and attempts to launch the forensic AMI. The EC2 instance launches and immediately terminates. What should the security learn do lo launch the EC2 instance successfully",
        "options": {
            "1": "Update the policy that is associated with the federated IAM role to allow the ec2. Describelmages action for the forensic AMI.",
            "2": "Update the policy that is associated with the federated IAM role to allow the ec2 Start Instances action m the security team's AWS account.",
            "3": "Update the policy that is associated with the KMS key that is used to encrypt the forensic AMI. Configure the policy to allow the kms. Encrypt and kms Decrypt actions for the federated IAM role.",
            "4": "Update the policy that is associated with the federated IAM role to allow the kms. DescribeKey action for the KMS key that is used to encrypt the forensic AMI."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "75",
        "question": "A company wants to monitor the deletion of customer managed CMKs A security engineer must create an alarm that will notify the company before a CMK is deleted. The security engineer has configured the integration of IAM CloudTrail with Amazon CloudWatch What should the security engineer do next to meet this requirement?",
        "options": {
            "1": "Use inbound rule 100 to allow traffic on TCP port 443 Use inbound rule 200 to deny traffic on TCP port 3306 Use outbound rule 100 to allow traffic on TCP port 443.",
            "2": "Use inbound rule 100 to deny traffic on TCP port 3306. Use inbound rule 200 to allow traffic on TCP port range 1024-65535. Use outbound rule 100 to allow traffic on TCP port 443.",
            "3": "Use inbound rule 100 to allow traffic on TCP port range 1024-65535 Use inbound rule 200 to deny",
            "4": "Use inbound rule 100 to deny traffic on TCP port 3306 Use inbound rule 200 to allow traffic on TCP port 443 Use outbound rule 100 to allow traffic on TCP port 443."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "76",
        "question": "A company is building an application on IAM that will store sensitive Information. The company has a support team with access to the IT infrastructure, including databases. The company's security engineer must introduce measures to protect the sensitive data against any data breach while minimizing management overhead. The credentials must be regularly rotated. What should the security engineer recommend?",
        "options": {
            "1": "Enable Amazon RDS encryption to encrypt the database and snapshots. Enable Amazon Elastic Block Store (Amazon EBS) encryption on Amazon EC2 instances. Include the database credential in the EC2 user data field. Use an IAM Lambda function to rotate database credentials. Set up TLS for the connection to the database.",
            "2": "Install a database on an Amazon EC2 Instance. Enable third-party disk encryption to encrypt the Amazon Elastic Block Store (Amazon EBS) volume. Store the database credentials in IAM CloudHSM with automatic rotation. Set up TLS for the connection to the database.",
            "3": "Enable Amazon RDS encryption to encrypt the database and snapshots. Enable Amazon Elastic Block Store (Amazon EBS) encryption on Amazon EC2 instances. Store the database credentials in IAM Secrets Manager with automatic rotation. Set up TLS for the connection to the RDS hosted database.",
            "4": "Set up an IAM CloudHSM cluster with IAM Key Management Service (IAM KMS) to store KMS keys. Set up Amazon RDS encryption using IAM KMS to encrypt the database. Store database credentials in the IAM Systems Manager Parameter Store with automatic rotation. Set up TLS for the connection to the RDS hosted database."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "77",
        "question": "A company deployed IAM Organizations to help manage its increasing number of IAM accounts. A security engineer wants to ensure only principals in the Organization structure can access a specic Amazon S3 bucket. The solution must also minimize operational overhead Which solution will meet these requirements?",
        "options": {
            "1": "1 Put all users into an IAM group with an access policy granting access to the J bucket.",
            "2": "Have the account creation trigger an IAM Lambda function that manages the bucket policy, allowing access to accounts listed in the policy only.",
            "3": "Add an SCP to the Organizations master account, allowing all principals access to the bucket.",
            "4": "Specify the organization ID in the global key condition element of a bucket policy, allowing all principals access."
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "78",
        "question": "A company is undergoing a layer 3 and layer 4 DDoS attack on its web servers running on IAM. Which combination of IAM services and features will provide protection in this scenario? (Select THREE)",
        "options": {
            "1": "Amazon Route 53.",
            "2": "IAM Certificate Manager (ACM).",
            "3": "Amazon S3.",
            "4": "IAM Shield.",
            "5": "Elastic Load Balancer.",
            "6": "Amazon Guard Duty."
        },
        "correct_answers": [
            "options.1",
            "options.4",
            "options.5"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "79",
        "question": "Your CTO thinks your IAM account was hacked. What is the only way to know for certain if there was unauthorized access and what they did, assuming your hackers are very sophisticated IAM engineers and doing everything they can to cover their tracks?",
        "options": {
            "1": "Use CloudTrail Log File Integrity Validation.",
            "2": "Use IAM Config SNS Subscriptions and process events in real time.",
            "3": "Use CloudTrail backed up to IAM S3 and Glacier.",
            "4": "Use IAM Config Timeline forensics."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "80",
        "question": "A company is developing a highly resilient application to be hosted on multiple Amazon EC2 instances. The application will store highly sensitive user data in Amazon RDS tables The application must \u2022 Include migration to a different IAM Region in the application disaster recovery plan. \u2022 Provide a full audit trail of encryption key administration events \u2022 Allow only company administrators to administer keys. \u2022 Protect data at rest using application layer encryption A Security Engineer is evaluating options for encryption key management Why should the Security Engineer choose IAM CloudHSM over IAM KMS for encryption key management in this situation?",
        "options": {
            "1": "The key administration event logging generated by CloudHSM is significantly more extensive than IAM KMS.",
            "2": "CloudHSM ensures that only company support staff can administer encryption keys, whereas IAM KMS allows IAM staff to administer keys",
            "3": "The ciphertext produced by CloudHSM provides more robust protection against brute force decryption attacks than the ciphertext produced by IAM KMS",
            "4": "CloudHSM provides the ability to copy keys to a different Region, whereas IAM KMS does not"
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "81",
        "question": "A company wants to ensure that its IAM resources can be launched only in the us-east-1 and us-west-2 Regions. What is the MOST operationally efficient solution that will prevent developers from launching Amazon EC2 instances in other Regions?",
        "options": {
            "1": "Enable Amazon GuardDuty in all Regions. Create alerts to detect unauthorized activity outside us-east-1 and us-west-2.",
            "2": "Use an organization in IAM Organizations. Attach an SCP that allows all actions when the IAM: Requested Region condition key is either us-east-1 or us-west-2. Delete the FullIAMAccess policy.",
            "3": "Provision EC2 resources by using IAM Cloud Formation templates through IAM CodePipeline. Allow only the values of us-east-1 and us-west-2 in the IAM CloudFormation template's parameters.",
            "4": "Create an IAM Config rule to prevent unauthorized activity outside us-east-1 and us-west-2."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "82",
        "question": "A company's Security Team received an email notification from the Amazon EC2 Abuse team that one or more of the company's Amazon EC2 instances may have been compromised Which combination of actions should the Security team take to respond to (be current modem? (Select TWO.)",
        "options": {
            "1": "Open a support case with the IAM Security team and ask them to remove the malicious code from the affected instance",
            "2": "Respond to the notification and list the actions that have been taken to address the incident",
            "3": "Delete all IAM users and resources in the account",
            "4": "Detach the internet gateway from the VPC remove aft rules that contain 0.0.0.0V0 from the security groups, and create a NACL rule to deny all traffic Inbound from the internet",
            "5": "Delete the identified compromised instances and delete any associated resources that the Security team did not create."
        },
        "correct_answers": [
            "options.2",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "83",
        "question": "A company is using Amazon Macie, AWS Firewall Manager, Amazon Inspector, and AWS Shield Advanced in its AWS account. The company wants to receive alerts if a DDoS attack occurs against the account. Which solution will meet this requirement?",
        "options": {
            "1": "Use Macie to detect an active DDoS event. Create Amazon CloudWatch alarms that respond to Macie findings.",
            "2": "Use Amazon Inspector to review resources and to invoke Amazon CloudWatch alarms for any resources that are vulnerable to DDoS attacks.",
            "3": "Create an Amazon CloudWatch alarm that monitors Firewall Manager metrics for an active DDoS event.",
            "4": "Create an Amazon CloudWatch alarm that monitors Shield Advanced metrics for an active DDoS event."
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "84",
        "question": "A company is running internal microservices on Amazon Elastic Container Service (Amazon ECS) with the Amazon EC2 launch type. The company is using Amazon Elastic Container Registry (Amazon ECR) private repositories. A security engineer needs to encrypt the private repositories by using AWS Key Management Service (AWS KMS). The security engineer also needs to analyze the container images for any common vulnerabilities and exposures (CVEs). Which solution will meet these requirements?",
        "options": {
            "1": "Enable KMS encryption on the existing ECR repositories. Install Amazon Inspector Agent from the ECS container instances' user data. Run an assessment with the CVE rules.",
            "2": "Recreate the ECR repositories with KMS encryption and ECR scanning enabled. Analyze the scan report after the next push of images.",
            "3": "Recreate the ECR repositories with KMS encryption and ECR scanning enabled. Install AWS Systems",
            "4": "Enable KMS encryption on the existing ECR repositories. Use AWS Trusted Advisor to check the ECS container instances and to verily the findings against a list of current CVEs."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "85",
        "question": "A business stores website images in an Amazon S3 bucket. The firm serves the photos to end users through Amazon CloudFront. The firm learned lately that the photographs are being accessible from nations in which it does not have a distribution license. Which steps should the business take to safeguard the photographs and restrict their distribution? (Select two.)",
        "options": {
            "1": "Update the S3 bucket policy to restrict access to a CloudFront origin access identity (OAI).",
            "2": "Update the website DNS record to use an Amazon Route 53 geolocation record deny list of countries where the company lacks a license.",
            "3": "Add a CloudFront geo restriction deny list of countries where the company lacks a license.",
            "4": "Update the S3 bucket policy with a deny list of countries where the company lacks a license.",
            "5": "Enable the Restrict Viewer Access option in CloudFront to create a deny list of countries where the company lacks a license."
        },
        "correct_answers": [
            "options.1",
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "86",
        "question": "A company wants to remove all SSH keys permanently from a specific subset of its Amazon Linux 2 Amazon EC2 instances that are using the same 1AM instance profile However three individuals who have IAM user accounts will need to access these instances by using an SSH session to perform critical duties How can a security engineer provide the access to meet these requirements?",
        "options": {
            "1": "Assign an 1AM policy to the instance profile to allow the EC2 instances to be managed by AWS Systems Manager Provide the 1AM user accounts with permission to use Systems Manager Remove the SSH keys from the EC2 instances Use Systems Manager Inventory to select the EC2 instance and connect.",
            "2": "Assign an 1AM policy to the 1AM user accounts to provide permission to use AWS Systems Manager Run Command Remove the SSH keys from the EC2 instances Use Run Command to open an SSH connection to the EC2 instance.",
            "3": "Assign an 1AM policy to the instance profile to allow the EC2 instances to be managed by AWS Systems Manager Provide the 1AM user accounts with permission to use Systems Manager Remove the SSH keys from the EC2 instances Use Systems Manager Session Manager to select the EC2 instance and connect.",
            "4": "Assign an 1AM policy to the 1AM user accounts to provide permission to use the EC2 service in the AWS Management Console Remove the SSH keys from the EC2 instances Connect to the EC2 instance as the ec2-user through the AWS Management Console's EC2 SSH client method."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "87",
        "question": "A security engineer is using AWS Organizations and wants to optimize SCPs. The security engineer needs to ensure that the SCPs conform to best practices. Which approach should the security engineer take to meet this requirement?",
        "options": {
            "1": "Use AWS IAM Access Analyzer to analyze the policies. View the findings from policy validation checks.",
            "2": "Review AWS Trusted Advisor checks for all accounts in the organization.",
            "3": "Set up AWS Audit Manager. Run an assessment for all AWS Regions for all accounts.",
            "4": "Ensure that Amazon Inspector agents are installed on all Amazon EC2 in-stances in all accounts."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "88",
        "question": "A company's security engineer has been tasked with restricting a contractor's IAM account access to the company's Amazon EC2 console without providing access to any other IAM services The contractors IAM account must not be able to gain access to any other IAM service, even it the IAM account rs assigned additional permissions based on IAM group membership What should the security engineer do to meet these requirements\u201d",
        "options": {
            "1": "Create an mime IAM user policy that allows for Amazon EC2 access for the contractor's IAM user.",
            "2": "Create an IAM permissions boundary policy that allows Amazon EC2 access Associate the contractor's IAM account with the IAM permissions boundary policy.",
            "3": "Create an IAM group with an attached policy that allows for Amazon EC2 access Associate the contractor's IAM account with the IAM group.",
            "4": "Create a IAM role that allows for EC2 and explicitly denies all other services Instruct the contractor to always assume this role."
        },
        "correct_answers": [],
        "description": "",
        "source_url": ""
    },
    {
        "id": "89",
        "question": "A company is using AWS Organizations to manage multiple accounts. The company needs to allow an IAM user to use a role to access resources that are in another organization's AWS account. Which combination of steps must the company perform to meet this requirement? (Select TWO.)",
        "options": {
            "1": "Create an identity policy that allows the sts: AssumeRole action in the AWS account that contains the resources. Attach the identity policy to the IAM user.",
            "2": "Ensure that the sts: AssumeRole action is allowed by the SCPs of the organization that owns the resources that the IAM user needs to access.",
            "3": "Create a role in the AWS account that contains the resources. Create an entry in the role's trust policy that allows the IAM user to assume the role. Attach the trust policy to the role.",
            "4": "Establish a trust relationship between the IAM user and the AWS account that contains the resources.",
            "5": "Create a role in the IAM user's AWS account. Create an identity policy that allows the sts: AssumeRole action. Attach the identity policy to the role."
        },
        "correct_answers": [
            "options.1",
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "90",
        "question": "A company's AWS CloudTrail logs are all centrally stored in an Amazon S3 bucket. The security team controls the company's AWS account. The security team must prevent unauthorized access and tampering of the CloudTrail logs. Which combination of steps should the security team take? (Choose three.)",
        "options": {
            "1": "Configure server-side encryption with AWS KMS managed encryption keys (SSE-KMS).",
            "2": "Compress log file with secure gzip.",
            "3": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule to notify the security team of any modifications on CloudTrail log files.",
            "4": "Implement least privilege access to the S3 bucket by configuring a bucket policy.",
            "5": "Configure CloudTrail log file integrity validation.",
            "6": "Configure Access Analyzer for S3."
        },
        "correct_answers": [
            "options.1",
            "options.4",
            "options.5"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "91",
        "question": "A company stores sensitive documents in Amazon S3 by using server-side encryption with an IAM Key Management Service (IAM KMS) CMK. A new requirement mandates that the CMK that is used for these documents can be used only for S3 actions. Which statement should the company add to the key policy to meet this requirement? <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question91_1.jpg' alt='Question 91 part 1'> <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question91_2.jpg' alt='Question 91 part 2'>",
        "options": {
            "1": "Option A.",
            "2": "Option B."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "92",
        "question": "A Security Engineer receives alerts that an Amazon EC2 instance on a public subnet is under an SFTP brute force attack from a specific IP address, which is a known malicious bot. What should the Security Engineer do to block the malicious bot?",
        "options": {
            "1": "Add a deny rule to the public VPC security group to block the malicious IP.",
            "2": "Add the malicious IP to IAM WAF backhsted IPs.",
            "3": "Configure Linux iptables or Windows Firewall to block any traffic from the malicious IP.",
            "4": "Modify the hosted zone in Amazon Route 53 and create a DNS sinkhole for the malicious IP."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "93",
        "question": "A systems engineer deployed containers from several custom-built images that an application team provided through a QA workflow The systems engineer used Amazon Elastic Container Service (Amazon ECS) with the Fargate launch type as the target platform The system engineer now needs to collect logs from all containers into an existing Amazon CloudWatch log group Which solution will meet this requirement?",
        "options": {
            "1": "Turn on the awslogs log driver by specifying parameters for awslogs-group and awslogs-region m the LogConfiguration property.",
            "2": "Download and configure the CloudWatch agent on the container instances.",
            "3": "Set up Fluent Bit and FluentO as a DaemonSet to send logs to Amazon CloudWatch Logs.",
            "4": "Configure an 1AM policy that includes the togs CreateLogGroup action Assign the policy to the container instances."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "94",
        "question": "A recent security audit found that IAM CloudTrail logs are insufficiently protected from tampering and unauthorized access Which actions must the Security Engineer take to address these audit findings? (Select THREE)",
        "options": {
            "1": "Ensure CloudTrail log file validation is turned on.",
            "2": "Configure an S3 lifecycle rule to periodically archive CloudTrail logs into Glacier for long-term storage.",
            "3": "Use an S3 bucket with tight access controls that exists m a separate account.",
            "4": "Use Amazon Inspector to monitor the file integrity of CloudTrail log files.",
            "5": "Request a certificate through ACM and use a generated certificate private key to encrypt CloudTrail log files.",
            "6": "Encrypt the CloudTrail log files with server-side encryption with IAM KMS-managed keys (SSE-KMS)."
        },
        "correct_answers": [
            "options.1",
            "options.3",
            "options.6"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "95",
        "question": "Auditors for a health care company have mandated that all data volumes be encrypted at rest Infrastructure is deployed mainly via IAM CloudFormation however third-party frameworks and manual deployment are required on some legacy systems What is the BEST way to monitor, on a recurring basis, whether all EBS volumes are encrypted?",
        "options": {
            "1": "On a recurring basis, update an IAM user policies to require that EC2 instances are created with an encrypted volume.",
            "2": "Configure an IAM Config rule lo run on a recurring basis \u2018or volume encryption.",
            "3": "Set up Amazon Inspector rules tor volume encryption to run on a recurring schedule.",
            "4": "Use CloudWatch Logs to determine whether instances were created with an encrypted volume."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "96",
        "question": "A startup company is using a single AWS account that has resources in a single AWS Region. A security engineer configures an AWS Cloud Trail trail in the same Region to deliver log files to an Amazon S3 bucket by using the AWS CLI. Because of expansion, the company adds resources in multiple Regions. The security engineer notices that the logs from the new Regions are not reaching the S3 bucket. What should the security engineer do to fix this issue with the LEAST amount of operational overhead?",
        "options": {
            "1": "Create a new CloudTrail trail. Select the new Regions where the company added resources.",
            "2": "Change the S3 bucket to receive notifications to track all actions from all Regions.",
            "3": "Create a new CloudTrail trail that applies to all Regions.",
            "4": "Change the existing CloudTrail trail so that it applies to all Regions."
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "97",
        "question": "A company's cloud operations team is responsible for building effective security for IAM cross-account access. The team asks a security engineer to help troubleshoot why some developers in the developer account (123456789012) in the developers group are not able to assume a cross-account role (ReadS3) into a production account (999999999999) to read the contents of an Amazon S3 bucket (productionapp). The two account policies are as follows: Which recommendations should the security engineer make to resolve this issue? (Select TWO.) <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question97.jpg' alt='Question 97'>",
        "options": {
            "1": "Ask the developers to change their password and use a different web browser.",
            "2": "Ensure that developers are using multi-factor authentication (MFA) when they log in to their developer account as the developer role.",
            "3": "Modify the production account ReadS3 role policy to allow the PutBucketPolicy action on the productionapp S3 bucket.",
            "4": "Update the trust relationship policy on the production account S3 role to allow the account number of the developer account.",
            "5": "Update the developer group permissions in the developer account to allow access to the productionapp S3 bucket."
        },
        "correct_answers": [
            "options.1",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "98",
        "question": "A company deploys a distributed web application on a fleet of Amazon EC2 instances. The fleet is behind an Application Load Balancer (ALB) that will be configured to terminate the TLS connection. All TLS traffic to the ALB must stay secure, even if the certificate private key is compromised. How can a security engineer meet this requirement?",
        "options": {
            "1": "Create an HTTPS listener that uses a certificate that is managed by IAM Certificate Manager (ACM).",
            "2": "Create an HTTPS listener that uses a security policy that uses a cipher suite with perfect toward secrecy (PFS).",
            "3": "Create an HTTPS listener that uses the Server Order Preference security feature.",
            "4": "Create a TCP listener that uses a custom security policy that allows only cipher suites with perfect forward secrecy (PFS)."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "99",
        "question": "A company's public Application Load Balancer (ALB) recently experienced a DDoS attack. To mitigate this issue. the company deployed Amazon CloudFront in front of the ALB so that users would not directly access the Amazon EC2 instances behind the ALB. The company discovers that some traffic is still coming directly into the ALB and is still being handled by the EC2 instances. Which combination of steps should the company take to ensure that the EC2 instances will receive traffic only from CloudFront? (Choose two.)",
        "options": {
            "1": "Configure CloudFront to add a cache key policy to allow a custom HTTP header that CloudFront sends to the ALB.",
            "2": "Configure CloudFront to add a custom: HTTP header to requests that CloudFront sends to the ALB.",
            "3": "Configure the ALB to forward only requests that contain the custom HTTP header.",
            "4": "Configure the ALB and CloudFront to use the X-Forwarded-For header to check client IP addresses.",
            "5": "Configure the ALB and CloudFront to use the same X.509 certificate that is generated by AWS Certificate Manager (ACM)."
        },
        "correct_answers": [
            "options.2",
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "100",
        "question": "A company h as a legacy application that runs on a single Amazon E C2 instance. A security audit shows that the application has been using an IAM access key within its code to access an Amazon S3 bucket that is named DOC-EXAMPLE-BUCKET1 in the same AWS account. This access key pair has the s3:GetObject permission to all objects in only this S3 bucket. The company takes the application offline because the application is not compliant with the company's security policies for accessing other AWS resources from Amazon EC2. A security engineer validates that AWS CloudTrail is turned on in all AWS Regions. CloudTrail is sending logs to an S3 bucket that is named DOC-EXAMPLE-BUCKET2. This S3 bucket is in the same AWS account as DOC-EXAMPLE-BUCKET1. However, CloudTrail has not been configured to send logs to Amazon CloudWatch Logs. The company wants to know if any objects in DOC-EXAMPLE-BUCKET1 were accessed with the IAM access key in the past 60 days. If any objects were accessed, the company wants to know if any of the objects that are text files (.txt extension) contained personally identifiable information (PII). Which combination of steps should the security engineer take to gather this information? (Choose two.)",
        "options": {
            "1": "Configure Amazon Macie to identify any objects in DOC-EXAMPLE-BUCKET1 that contain PII and that were available to the access key.",
            "2": "Use Amazon CloudWatch Logs Insights to identify any objects in DOC-EXAMPLE-BUCKET1 that contain PII and that were available to the access key.",
            "3": "Use Amazon OpenSearch Service (Amazon Elasticsearch Service) to query the CloudTrail logs in DOC-EXAMPLE-BUCKET2 for API calls that used the access key to access an object that contained PII.",
            "4": "Use Amazon Athena to query the CloudTrail logs in DOC-EXAMPLE-BUCKET2 for any API calls that used the access key to access an object that contained PII.",
            "5": "Use AWS Identity and Access Management Access Analyzer to identify any API calls that used the access key to access objects that contained PII in DOC-EXAMPLE-BUCKET1."
        },
        "correct_answers": [
            "options.1",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "101",
        "question": "A security engineer is configuring a new website that is named example.com. The security engineer wants to secure communications with the website by requiring users to connect to example.com through HTTPS. Which of the following is a valid option for storing SSL/TLS certificates?",
        "options": {
            "1": "Custom SSL certificate that is stored in AWS Key Management Service (AWS KMS).",
            "2": "Default SSL certificate that is stored in Amazon CloudFront.",
            "3": "Custom SSL certificate that is stored in AWS Certificate Manager (ACM).",
            "4": "Default SSL certificate that is stored in Amazon S3."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "102",
        "question": "A security engineer needs to develop a process to investigate and respond to potential security events on a company's Amazon EC2 instances. All the EC2 instances are backed by Amazon Elastic Block Store (Amazon EBS). The company uses AWS Systems Manager to manage all the EC2 instances and has installed Systems Manager Agent (SSM Agent) on all the EC2 instances. The process that the security engineer is developing must comply with AWS security best practices and must meet the following requirements: A compromised EC2 instance's volatile memory and non-volatile memory must be preserved for forensic purposes. A compromised EC2 instance's metadata must be updated with corresponding incident ticket information. A compromised EC2 instance must remain online during the investigation but must be isolated to prevent the spread of malware. Any investigative activity during the collection of volatile data must be captured as part of the process. Which combination of steps should the security engineer take to meet these requirements with the LEAST operational overhead? (Choose three.)",
        "options": {
            "1": "Gather any relevant metadata for the compromised EC2 instance. Enable termination protection. Isolate the instance by updating the instance's security groups to restrict access. Detach the instance from any Auto Scaling groups that the instance is a member of. Deregister the instance from any Elastic Load Balancing (ELB) resources.",
            "2": "Gather any relevant metadata for the compromised EC2 instance. Enable termination protection. Move the instance to an isolation subnet that denies all source and destination traffic. Associate the instance with the subnet to restrict access. Detach the instance from any Auto Scaling groups that the instance is a member of. Deregister the instance from any Elastic Load Balancing (ELB) resources.",
            "3": "Use Systems Manager Run Command to invoke scripts that collect volatile data.",
            "4": "Establish a Linux SSH or Windows Remote Desktop Protocol (RDP) session to the compromised EC2 instance to invoke scripts that collect volatile data.",
            "5": "Create a snapshot of the compromised EC2 instance's EBS volume for follow-up investigations. Tag the instance with any relevant metadata and incident ticket information.",
            "6": "Create a Systems Manager State Manager association to generate an EBS volume snapshot of the compromised EC2 instance. Tag the instance with any relevant metadata and incident ticket information."
        },
        "correct_answers": [
            "options.2",
            "options.3",
            "options.5"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "103",
        "question": "A company has an organization in AWS Organizations. The company wants to use AWS CloudFormation StackSets in the organization to deploy various AWS design patterns into environments. These patterns consist of Amazon EC2 instances, Elastic Load Balancing (ELB) load balancers, Amazon RDS databases, and Amazon Elastic Kubernetes Service (Amazon EKS) clusters or Amazon Elastic Container Service (Amazon ECS) clusters. Currently, the company's developers can create their own CloudFormation stacks to increase the overall speed of delivery. A centralized CI/CD pipeline in a shared services AWS account deploys each CloudFormation stack. The company's security team has already provided requirements for each service in accordance with internal standards. If there are any resources that do not comply with the internal standards, the security team must receive notification to take appropriate action. The security team must implement a notification solution that gives developers the ability to maintain the same overall delivery speed that they currently have. Which solution will meet these requirements in the MOST operationally efficient way?",
        "options": {
            "1": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the security team's email addresses to the SNS topic. Create a custom AWS Lambda function that will run the aws cloudformation validate-template AWS CLI command on all CloudFormation templates before the build stage in the CI/CD pipeline. Configure the CI/CD pipeline to publish a notification to the SNS topic if any issues are found.",
            "2": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the security team's email addresses to the SNS topic. Create custom rules in CloudFormation Guard for each resource configuration. In the CI/CD pipeline, before the build stage, configure a Docker image to run the cfn-guard command on the CloudFormation template. Configure the CI/CD pipeline to publish a notification to the SNS topic if any issues are found.",
            "3": "Create an Amazon Simple Notification Service (Amazon SNS) topic and an Amazon Simple Queue Service (Amazon SQS) queue. Subscribe the security team's email addresses to the SNS topic. Create an Amazon S3 bucket in the shared services AWS account. Include an event notification to publish to the SQS queue when new objects are added to the S3 bucket. Require the developers to put their CloudFormation templates in the S3 bucket. Launch EC2 instances that automatically scale based on the SQS queue depth. Configure the EC2 instances to use CloudFormation Guard to scan the templates and deploy the templates if there are no issues. Configure the CI/CD pipeline to publish a notification to the SNS topic if any issues are found.",
            "4": "Create a centralized CloudFormation stack set that includes a standard set of resources that the developers can deploy in each AWS account. Configure each CloudFormation template to meet the security requirements. For any new resources or configurations, update the CloudFormation template and send the template to the security team for review. When the review is completed, add the new CloudFormation stack to the repository for the developers to use."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "104",
        "question": "A company is migrating one of its legacy systems from an on-premises data center to AWS. The application server will run on AWS, but the database must remain in the on-premises data center for compliance reasons. The database is sensitive to network latency. Additionally, the data that travels between the on-premises data center and AWS must have IPsec encryption. Which combination of AWS solutions will meet these requirements? (Choose two.)",
        "options": {
            "1": "AWS Site-to-Site VPN",
            "2": "AWS Direct Connect",
            "3": "AWS VPN CloudHub",
            "4": "VPC peering",
            "5": "NAT gateway"
        },
        "correct_answers": [
            "options.1",
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "105",
        "question": "A company has an application that uses dozens of Amazon DynamoDB tables to store data. Auditors find that the tables do not comply with the company's data protection policy. The company's retention policy states that all data must be backed up twice each month: once at midnight on the 15th day of the month and again at midnight on the 25th day of the month. The company must retain the backups for 3 months. Which combination of steps should a security engineer take to meet these requirements? (Choose two.)",
        "options": {
            "1": "Use the DynamoDB on-demand backup capability to create a backup plan. Configure a lifecycle policy to expire backups after 3 months.",
            "2": "Use AWS DataSync to create a backup plan. Add a backup rule that includes a retention period of 3 months.",
            "3": "Use AWS Backup to create a backup plan. Add a backup rule that includes a retention period of 3 months.",
            "4": "Set the backup frequency by using a cron schedule expression. Assign each DynamoDB table to the backup plan.",
            "5": "Set the backup frequency by using a rate schedule expression. Assign each DynamoDB table to the backup plan."
        },
        "correct_answers": [
            "options.3",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "106",
        "question": "A company needs a security engineer to implement a scalable solution for multi-account authentication and authorization. The solution should not introduce additional user-managed architectural components. Native AWS features should be used as much as possible. The security engineer has set up AWS Organizations with all features activated and AWS IAM Identity Center (AWS Single Sign-On) enabled. Which additional steps should the security engineer take to complete the task?",
        "options": {
            "1": "Use AD Connector to create users and groups for all employees that require access to AWS accounts. Assign AD Connector groups to AWS accounts and link to the IAM roles in accordance with the employees' job functions and access requirements. Instruct employees to access AWS accounts by using the AWS Directory Service user portal.",
            "2": "Use an IAM Identity Center default directory to create users and groups for all employees that require access to AWS accounts. Assign groups to AWS accounts and link to permission sets in accordance with the employees' job functions and access requirements. Instruct employees to access AWS accounts by using the IAM Identity Center user portal.",
            "3": "Use an IAM Identity Center default directory to create users and groups for all employees that require access to AWS accounts. Link IAM Identity Center groups to the IAM users present in all accounts to inherit existing permissions. Instruct employees to access AWS accounts by using the IAM Identity Center user portal.",
            "4": "Use an IAM Identity Center default directory to create users and groups for all employees that require access to AWS accounts. Link IAM Identity Center groups to the IAM users present in all accounts to inherit existing permissions. Instruct employees to access AWS accounts by using the IAM Identity Center user portal."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "107",
        "question": "A company has an AWS account that hosts a production application. The company receives an email notification that Amazon GuardDuty has detected an Impact:IAMUser/AnomalousBehavior finding in the account. A security engineer needs to run the investigation playbook for this security incident and must collect and analyze the information without affecting the application. Which solution will meet these requirements MOST quickly?",
        "options": {
            "1": "Log in to the AWS account by using read-only credentials. Review the GuardDuty finding for details about the IAM credentials that were used. Use the IAM console to add a DenyAll policy to the IAM principal.",
            "2": "Log in to the AWS account by using read-only credentials. Review the GuardDuty finding to determine which API calls initiated the finding. Use Amazon Detective to review the API calls in context.",
            "3": "Log in to the AWS account by using administrator credentials. Review the GuardDuty finding for details about the IAM credentials that were used. Use the IAM console to add a DenyAll policy to the IAM principal.",
            "4": "Log in to the AWS account by using read-only credentials. Review the GuardDuty finding to determine which API calls initiated the finding. Use AWS CloudTrail Insights and AWS CloudTrail Lake to review the API calls in context."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "108",
        "question": "A company wants to receive an email notification about critical findings in AWS Security Hub. The company does not have an existing architecture that supports this functionality. Which solution will meet the requirement?",
        "options": {
            "1": "Create an AWS Lambda function to identify critical Security Hub findings. Create an Amazon Simple Notification Service (Amazon SNS) topic as the target of the Lambda function. Subscribe an email endpoint to the SNS topic to receive published messages.",
            "2": "Create an Amazon Kinesis Data Firehose delivery stream. Integrate the delivery stream with Amazon EventBridge. Create an EventBridge rule that has a filter to detect critical Security Hub findings. Configure the delivery stream to send the findings to an email address.",
            "3": "Create an Amazon EventBridge rule to detect critical Security Hub findings. Create an Amazon Simple Notification Service (Amazon SNS) topic as the target of the EventBridge rule. Subscribe an email endpoint to the SNS topic to receive published messages.",
            "4": "Create an Amazon EventBridge rule to detect critical Security Hub findings. Create an Amazon Simple Email Service (Amazon SES) topic as the target of the EventBridge rule. Use the Amazon SES API to format the message. Choose an email address to be the recipient of the message."
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "109",
        "question": "An international company has established a new business entity in South Korea. The company also has established a new AWS account to contain the workload for the South Korean region. The company has set up the workload in the new account in the ap-northeast-2 Region. The workload consists of three Auto Scaling groups of Amazon EC2 instances. All workloads that operate in this Region must keep system logs and application logs for 7 years. A security engineer must implement a solution to ensure that no logging data is lost for each instance during scaling activities. The solution also must keep the logs for only the required period of 7 years. Which combination of steps should the security engineer take to meet these requirements? (Choose three.)",
        "options": {
            "1": "Ensure that the Amazon CloudWatch agent is installed on all the EC2 instances that the Auto Scaling groups launch. Generate a CloudWatch agent configuration file to forward the required logs to Amazon CloudWatch Logs.",
            "2": "Set the log retention for desired log groups to 7 years.",
            "3": "Attach an IAM role to the launch configuration or launch template that the Auto Scaling groups use. Configure the role to provide the necessary permissions to forward logs to Amazon CloudWatch Logs.",
            "4": "Attach an IAM role to the launch configuration or launch template that the Auto Scaling groups use. Configure the role to provide the necessary permissions to forward logs to Amazon S3.",
            "5": "Ensure that a log forwarding application is installed on all the EC2 instances that the Auto Scaling groups launch. Configure the log forwarding application to periodically bundle the logs and forward the logs to Amazon S3.",
            "6": "Configure an Amazon S3 Lifecycle policy on the target S3 bucket to expire objects after 7 years."
        },
        "correct_answers": [
            "options.1",
            "options.2",
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "110",
        "question": "A security engineer is designing an IAM policy to protect AWS API operations. The policy must enforce multi-factor authentication (MFA) for IAM users to access certain services in the AWS production account. Each session must remain valid for only 2 hours. The current version of the IAM policy is as follows: Which combination of conditions must the security engineer add to the IAM policy to meet these requirements? (Choose two.) <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question110.png' alt='Question 110'>",
        "options": {
            "1": "\"Bool\": {\"aws:MultiFactorAuthPresent\": \"true\"}",
            "2": "\"Bool\": {\"aws:MultiFactorAuthPresent\": \"false\"}",
            "3": "\"NumericLessThan\": {\"aws:MultiFactorAuthAge\": \"7200\"}",
            "4": "\"NumericGreaterThan\": {\"aws:MultiFactorAuthAge\": \"7200\"}",
            "5": "\"NumericLessThan\": {\"MaxSessionDuration\": \"7200\"}"
        },
        "correct_answers": [
            "options.1",
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "111",
        "question": "A company uses AWS Organizations and has production workloads across multiple AWS accounts. A security engineer needs to design a solution that will proactively monitor for suspicious behavior across all the accounts that contain production workloads. The solution must automate remediation of incidents across the production accounts. The solution also must publish a notification to an Amazon Simple Notification Service (Amazon SNS) topic when a critical security finding is detected. In addition, the solution must send all security incident logs to a dedicated account. Which solution will meet these requirements?",
        "options": {
            "1": "Activate Amazon GuardDuty in each production account. In a dedicated logging account, aggregate all GuardDuty logs from each production account. Remediate incidents by configuring GuardDuty to directly invoke an AWS Lambda function. Configure the Lambda function to also publish notifications to the SNS topic.",
            "2": "Activate AWS Security Hub in each production account. In a dedicated logging account, aggregate all Security Hub findings from each production account. Remediate incidents by using AWS Config and AWS Systems Manager. Configure Systems Manager to also publish notifications to the SNS topic.",
            "3": "Activate Amazon GuardDuty in each production account. In a dedicated logging account, aggregate all GuardDuty logs from each production account. Remediate incidents by using Amazon EventBridge to invoke a custom AWS Lambda function from the GuardDuty findings. Configure the Lambda function to also publish notifications to the SNS topic.",
            "4": "Activate AWS Security Hub in each production account. In a dedicated logging account, aggregate all Security Hub findings from each production account. Remediate incidents by using Amazon EventBridge to invoke a custom AWS Lambda function from the Security Hub findings. Configure the Lambda function to also publish notifications to the SNS topic."
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "112",
        "question": "A company is developing an ecommerce application. The application uses Amazon EC2 instances and an Amazon RDS MySQL database. For compliance reasons, data must be secured in transit and at rest. The company needs a solution that minimizes operational overhead and minimizes cost. Which solution meets these requirements?",
        "options": {
            "1": "Use TLS certificates from AWS Certificate Manager (ACM) with an Application Load Balancer. Deploy self-signed certificates on the EC2 instances. Ensure that the database client software uses a TLS connection to Amazon RDS. Enable encryption of the RDS DB instance. Enable encryption on the Amazon Elastic Block Store (Amazon EBS) volumes that support the EC2 instances.",
            "2": "Use TLS certificates from a third-party vendor with an Application Load Balancer. Install the same certificates on the EC2 instances. Ensure that the database client software uses a TLS connection to Amazon RDS. Use AWS Secrets Manager for client-side encryption of application data.",
            "3": "Use AWS CloudHSM to generate TLS certificates for the EC2 instances. Install the TLS certificates on the EC2 instances. Ensure that the database client software uses a TLS connection to Amazon RDS. Use the encryption keys from CloudHSM for client-side encryption of application data.",
            "4": "Use Amazon CloudFront with AWS WAF. Send HTTP connections to the origin EC2 instances. Ensure that the database client software uses a TLS connection to Amazon RDS. Use AWS Key Management Service (AWS KMS) for client-side encryption of application data before the data is stored in the RDS database."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "113",
        "question": "A security engineer is working with a company to design an ecommerce application. The application will run on Amazon EC2 instances that run in an Auto Scaling group behind an Application Load Balancer (ALB). The application will use an Amazon RDS DB instance for its database. The only required connectivity from the internet is for HTTP and HTTPS traffic to the application. The application must communicate with an external payment provider that allows traffic only from a preconfigured allow list of IP addresses. The company must ensure that communications with the external payment provider are not interrupted as the environment scales. Which combination of actions should the security engineer recommend to meet these requirements? (Choose three.)",
        "options": {
            "1": "Deploy a NAT gateway in each private subnet for every Availability Zone that is in use.",
            "2": "Place the DB instance in a public subnet.",
            "3": "Place the DB instance in a private subnet.",
            "4": "Configure the Auto Scaling group to place the EC2 instances in a public subnet.",
            "5": "Configure the Auto Scaling group to place the EC2 instances in a private subnet.",
            "6": "Deploy the ALB in a private subnet."
        },
        "correct_answers": [
            "options.4",
            "options.5",
            "options.6"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "114",
        "question": "A company uses several AWS CloudFormation stacks to handle the deployment of a suite of applications. The leader of the company's application development team notices that the stack deployments fail with permission errors when some team members try to deploy the stacks. However, other team members can deploy the stacks successfully. The team members access the account by assuming a role that has a specific set of permissions that are necessary for the job responsibilities of the team members. All team members have permissions to perform operations on the stacks. Which combination of steps will ensure consistent deployment of the stacks MOST securely? (Choose three.)",
        "options": {
            "1": "Create a service role that has a composite principal that contains each service that needs the necessary permissions. Configure the role to allow the sts:AssumeRole action.",
            "2": "Create a service role that has cloudformation.amazonaws.com as the service principal. Configure the role to allow the sts:AssumeRole action.",
            "3": "For each required set of permissions, add a separate policy to the role to allow those permissions. Add the ARN of each CloudFormation stack in the resource field of each policy.",
            "4": "For each required set of permissions, add a separate policy to the role to allow those permissions. Add the ARN of each service that needs the permissions in the resource field of the corresponding policy.",
            "5": "Update each stack to use the service role.",
            "6": "Add a policy to each member role to allow the iam:PassRole action. Set the policy's resource field to the ARN of the service role."
        },
        "correct_answers": [
            "options.1",
            "options.4",
            "options.5"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "115",
        "question": "A company used a lift-and-shift approach to migrate from its on-premises data centers to the AWS Cloud. The company migrated on-premises VMs to Amazon EC2 instances. Now the company wants to replace some of components that are running on the EC2 instances with managed AWS services that provide similar functionality. Initially, the company will transition from load balancer software that runs on EC2 instances to AWS Elastic Load Balancers. A security engineer must ensure that after this transition, all the load balancer logs are centralized and searchable for auditing. The security engineer must also ensure that metrics are generated to show which ciphers are in use. Which solution will meet these requirements?",
        "options": {
            "1": "Create an Amazon CloudWatch Logs log group. Configure the load balancers to send logs to the log group. Use the CloudWatch Logs console to search the logs. Create CloudWatch Logs filters on the logs for the required metrics.",
            "2": "Create an Amazon S3 bucket. Configure the load balancers to send logs to the S3 bucket. Use Amazon Athena to search the logs that are in the S3 bucket. Create Amazon CloudWatch filters on the S3 log files for the required metrics.",
            "3": "Create an Amazon S3 bucket. Configure the load balancers to send logs to the S3 bucket. Use Amazon Athena to search the logs that are in the S3 bucket. Create Athena queries for the required metrics. Publish the metrics to Amazon CloudWatch.",
            "4": "Create an Amazon CloudWatch Logs log group. Configure the load balancers to send logs to the log group. Use the AWS Management Console to search the logs. Create Amazon Athena queries for the required metrics. Publish the metrics to Amazon CloudWatch."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "116",
        "question": "A company has a legacy application that runs on a single Amazon EC2 instance. A security audit shows that the application has been using an IAM access key within its code to access an Amazon S3 bucket that is named DOC-EXAMPLE-BUCKET1 in the same AWS account. This access key pair has the s3:GetObject permission to all objects in only this S3 bucket. The company takes the application offline because the application is not compliant with the company's security policies for accessing other AWS resources from Amazon EC2. A security engineer validates that AWS CloudTrail is turned on in all AWS Regions. CloudTrail is sending logs to an S3 bucket that is named DOC-EXAMPLE-BUCKET2. This S3 bucket is in the same AWS account as DOC-EXAMPLE-BUCKET1. However, CloudTrail has not been configured to send logs to Amazon CloudWatch Logs. The company wants to know if any objects in DOC-EXAMPLE-BUCKET1 were accessed with the IAM access key in the past 60 days. If any objects were accessed, the company wants to know if any of the objects that are text files (.txt extension) contained personally identifiable information (PII). Which combination of steps should the security engineer take to gather this information? (Choose two.)",
        "options": {
            "1": "Use Amazon CloudWatch Logs Insights to identify any objects in DOC-EXAMPLE-BUCKET1 that contain PII and that were available to the access key.",
            "2": "Use Amazon OpenSearch Service to query the CloudTrail logs in DOC-EXAMPLE-BUCKET2 for API calls that used the access key to access an object that contained PII.",
            "3": "Use Amazon Athena to query the CloudTrail logs in DOC-EXAMPLE-BUCKET2 for any API calls that used the access key to access an object that contained PII.",
            "4": "Use AWS Identity and Access Management Access Analyzer to identify any API calls that used the access key to access objects that contained PII in DOC-EXAMPLE-BUCKET1.",
            "5": "Configure Amazon Macie to identify any objects in DOC-EXAMPLE-BUCKET1 that contain PII and that were available to the access key."
        },
        "correct_answers": [
            "options.1",
            "options.5"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "117",
        "question": "A security engineer creates an Amazon S3 bucket policy that denies access to all users. A few days later, the security engineer adds an additional statement to the bucket policy to allow read-only access to one other employee. Even after updating the policy, the employee sill receives an access denied message. What is the likely cause of this access denial?",
        "options": {
            "1": "The ACL in the bucket needs to be updated.",
            "2": "The IAM policy does not allow the user to access the bucket.",
            "3": "It takes a few minutes for a bucket policy to take effect.",
            "4": "The allow permission is being overridden by the deny."
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "118",
        "question": "While securing the connection between a company's VPC and its on-premises data center, a security engineer sent a ping command from an on-premises host (IP address 203.0.113.12) to an Amazon EC2 instance (IP address 172.31.16.139). The ping command did not return a response. The flow log in the VPC showed the following: What action should be performed to allow the ping to work? <br><img src='resources\\tests\\AWS-Certified-Security-SCS-C02\\images\\question118.jpg' alt='Question 118'>",
        "options": {
            "1": "In the security group of the EC2 instance, allow inbound ICMP traffic.",
            "2": "In the security group of the EC2 instance, allow outbound ICMP traffic.",
            "3": "In the VPC's NACL, allow inbound ICMP traffic.",
            "4": "In the VPC's NACL, allow outbound ICMP traffic."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "119",
        "question": "What are the MOST secure ways to protect the AWS account root user of a recently opened AWS account? (Choose two.)",
        "options": {
            "1": "Use the AWS account root user access keys instead of the AWS Management Console.",
            "2": "Enable multi-factor authentication for the AWS IAM users with the AdministratorAccess managed policy attached to them.",
            "3": "Use AWS KMS to encrypt all AWS account root user and AWS IAM access keys and set automatic rotation to 30 days.",
            "4": "Do not create access keys for the AWS account root user; instead, create AWS IAM users.",
            "5": "Enable multi-factor authentication for the AWS account root user."
        },
        "correct_answers": [
            "options.3",
            "options.5"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "120",
        "question": "A company is expanding its group of stores. On the day that each new store opens, the company wants to launch a customized web application for that store. Each store's application will have a non-production environment and a production environment. Each environment will be deployed in a separate AWS account. The company uses AWS Organizations and has an OU that is used only for these accounts. The company distributes most of the development work to third-party development teams. A security engineer needs to ensure that each team follows the company's deployment plan for AWS resources. The security engineer also must limit access to the deployment plan to only the developers who need access. The security engineer already has created an AWS CloudFormation template that implements the deployment plan. What should the security engineer do next to meet the requirements in the MOST secure way?",
        "options": {
            "1": "Create an AWS Service Catalog portfolio in the organization's management account. Upload the CloudFormation template. Add the template to the portfolio's product list. Share the portfolio with the OU.",
            "2": "Use the CloudFormation CLI to create a module from the CloudFormation template. Register the module as a private extension in the CloudFormation registry. Publish the extension. In the OU, create an SCP that allows access to the extension.",
            "3": "Create an AWS Service Catalog portfolio in the organization's management account. Upload the CloudFormation template. Add the template to the portfolio's product list. Create an IAM role that has a trust policy that allows cross-account access to the portfolio for users in the OU accounts. Attach the AWSServiceCatalogEndUserFullAccess managed policy to the role.",
            "4": "Use the CloudFormation CLI to create a module from the CloudFormation template. Register the module as a private extension in the CloudFormation registry. Publish the extension. Share the extension with the OU."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "121",
        "question": "A company is hosting a web application on Amazon EC2 instances behind an Application Load Balancer (ALB). The application has become the target of a DoS attack. Application logging shows that requests are coming from a small number of client IP addresses, but the addresses change regularly. The company needs to block the malicious traffic with a solution that requires the least amount of ongoing effort. Which solution meets these requirements?",
        "options": {
            "1": "Create an AWS WAF rate-based rule, and attach it to the ALB.",
            "2": "Update the security group that is attached to the ALB to block the attacking IP addresses.",
            "3": "Update the ALB subnet's network ACL to block the attacking client IP addresses.",
            "4": "Create an AWS WAF rate-based rule, and attach it to the security group of the EC2 instances."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "122",
        "question": "A company has hundreds of AWS accounts in an organization in AWS Organizations. The company operates out of a single AWS Region. The company has a dedicated security tooling AWS account in the organization. The security tooling account is configured as the organization's delegated administrator for Amazon GuardDuty and AWS Security Hub. The company has configured the environment to automatically enable GuardDuty and Security Hub for existing AWS accounts and new AWS accounts. The company is performing control tests on specific GuardDuty findings to make sure that the company's security team can detect and respond to security events. The security team launched an Amazon EC2 instance and attempted to run DNS requests against a test domain, example.com, to generate a DNS finding. However, the GuardDuty finding was never created in the Security Hub delegated administrator account. Why was the finding was not created in the Security Hub delegated administrator account?",
        "options": {
            "1": "VPC flow logs were not turned on for the VPC where the EC2 instance was launched.",
            "2": "The VPC where the EC2 instance was launched had the DHCP option configured for a custom OpenDNS resolver.",
            "3": "The GuardDuty integration with Security Hub was never activated in the AWS account where the finding was generated.",
            "4": "Cross-Region aggregation in Security Hub was not configured."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "123",
        "question": "An ecommerce company has a web application architecture that runs primarily on containers. The application containers are deployed on Amazon Elastic Container Service (Amazon ECS). The container images for the application are stored in Amazon Elastic Container Registry (Amazon ECR). The company's security team is performing an audit of components of the application architecture. The security team identifies issues with some container images that are stored in the container repositories. The security team wants to address these issues by implementing continual scanning and on-push scanning of the container images. The security team needs to implement a solution that makes any findings from these scans visible in a centralized dashboard. The security team plans to use the dashboard to view these findings along with other security-related findings that they intend to generate in the future. There are specific repositories that the security team needs to exclude from the scanning process. Which solution will meet these requirements?",
        "options": {
            "1": "Use Amazon Inspector. Create inclusion rules in Amazon ECR to match repositories that need to be scanned. Push Amazon Inspector findings to AWS Security Hub.",
            "2": "Use ECR basic scanning of container images. Create inclusion rules in Amazon ECR to match repositories that need to be scanned. Push findings to AWS Security Hub.",
            "3": "Use ECR basic scanning of container images. Create inclusion rules in Amazon ECR to match repositories that need to be scanned. Push findings to Amazon Inspector.",
            "4": "Use Amazon Inspector. Create inclusion rules in Amazon Inspector to match repositories that need to be scanned. Push Amazon Inspector findings to AWS Config."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "124",
        "question": "A company has a single AWS account and uses an Amazon EC2 instance to test application code. The company recently discovered that the instance was compromised. The instance was serving up malware. The analysis of the instance showed that the instance was compromised 35 days ago. A security engineer must implement a continuous monitoring solution that automatically notifies the company's security team about compromised instances through an email distribution list for high severity findings. The security engineer must implement the solution as soon as possible. Which combination of steps should the security engineer take to meet these requirements? (Choose three.)",
        "options": {
            "1": "Enable AWS Security Hub in the AWS account.",
            "2": "Enable Amazon GuardDuty in the AWS account.",
            "3": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the security team's email distribution list to the topic.",
            "4": "Create an Amazon Simple Queue Service (Amazon SQS) queue. Subscribe the security team's email distribution list to the queue.",
            "5": "Create an Amazon EventBridge rule for GuardDuty findings of high severity. Configure the rule to publish a message to the topic.",
            "6": "Create an Amazon EventBridge rule for Security Hub findings of high severity. Configure the rule to publish a message to the queue."
        },
        "correct_answers": [
            "options.2",
            "options.3",
            "options.5"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "125",
        "question": "A company is using AWS Organizations to manage multiple AWS accounts for its human resources, finance, software development, and production departments. All the company's developers are part of the software development AWS account. The company discovers that developers have launched Amazon EC2 instances that were preconfigured with software that the company has not approved for use. The company wants to implement a solution to ensure that developers can launch EC2 instances with only approved software applications and only in the software development AWS account. Which solution will meet these requirements?",
        "options": {
            "1": "In the software development account, create AMIs of preconfigured instances that include only approved software. Include the AMI IDs in the condition section of an AWS CloudFormation template to launch the appropriate AMI based on the AWS Region. Provide the developers with the CloudFormation template to launch EC2 instances in the software development account.",
            "2": "Create an Amazon EventBridge rule that runs when any EC2 RunInstances API event occurs in the software development account. Specify AWS Systems Manager Run Command as a target of the rule. Configure Run Command to run a script that will install all approved software onto the instances that the developers launch.",
            "3": "Use an AWS Service Catalog portfolio that contains EC2 products with appropriate AMIs that include only approved software. Grant the developers permission to access only the Service Catalog portfolio to launch a product in the software development account.",
            "4": "In the management account, create AMIs of preconfigured instances that include only approved software. Use AWS CloudFormation StackSets to launch the AMIs across any AWS account in the organization. Grant the developers permission to launch the stack sets within the management account."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "126",
        "question": "A company has enabled Amazon GuardDuty in all AWS Regions as part of its security monitoring strategy. In one of its VPCs, the company hosts an Amazon EC2 instance that works as an FTP server. A high number of clients from multiple locations contact the FTP server. GuardDuty identifies this activity as a brute force attack because of the high number of connections that happen every hour. The company has flagged the finding as a false positive, but GuardDuty continues to raise the issue. A security engineer must improve the signal-to-noise ratio without compromising the company's visibility of potential anomalous behavior. Which solution will meet these requirements?",
        "options": {
            "1": "Disable the FTP rule in GuardDuty in the Region where the FTP server is deployed.",
            "2": "Add the FTP server to a trusted IP list. Deploy the list to GuardDuty to stop receiving the notifications.",
            "3": "Create a suppression rule in GuardDuty to filter findings by automatically archiving new findings that match the specified criteria.",
            "4": "Create an AWS Lambda function that has the appropriate permissions to delete the finding whenever a new occurrence is reported."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "127",
        "question": "A company is running internal microservices on Amazon Elastic Container Service (Amazon ECS) with the Amazon EC2 launch type. The company is using Amazon Elastic Container Registry (Amazon ECR) private repositories. A security engineer needs to encrypt the private repositories by using AWS Key Management Service (AWS KMS). The security engineer also needs to analyze the container images for any common vulnerabilities and exposures (CVEs). Which solution will meet these requirements?",
        "options": {
            "1": "Enable KMS encryption on the existing ECR repositories. Install Amazon Inspector Agent from the ECS container instances' user data. Run an assessment with the CVE rules.",
            "2": "Recreate the ECR repositories with KMS encryption and ECR scanning enabled. Analyze the scan report after the next push of images.",
            "3": "Recreate the ECR repositories with KMS encryption and ECR scanning enabled. Install AWS Systems Manager Agent on the ECS container instances. Run an inventory report.",
            "4": "Enable KMS encryption on the existing ECR repositories. Use AWS Trusted Advisor to check the ECS container instances and to verify the findings against a list of current CVEs."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "128",
        "question": "A company's security engineer has been tasked with restricting a contractor's IAM account access to the company's Amazon EC2 console without providing access to any other AWS services. The contractor's IAM account must not be able to gain access to any other AWS service, even if the IAM account is assigned additional permissions based on IAM group membership. What should the security engineer do to meet these requirements?",
        "options": {
            "1": "Create an inline IAM user policy that allows for Amazon EC2 access for the contractor's IAM user.",
            "2": "Create an IAM permissions boundary policy that allows Amazon EC2 access. Associate the contractor's IAM account with the IAM permissions boundary policy.",
            "3": "Create an IAM group with an attached policy that allows for Amazon EC2 access. Associate the contractor's IAM account with the IAM group.",
            "4": "Create a IAM role that allows for EC2 and explicitly denies all other services. Instruct the contractor to always assume this role."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "129",
        "question": "A company manages multiple AWS accounts using AWS Organizations. The company's security team notices that some member accounts are not sending AWS CloudTrail logs to a centralized Amazon S3 logging bucket. The security team wants to ensure there is at least one trail configured for all existing accounts and for any account that is created in the future. Which set of actions should the security team implement to accomplish this?",
        "options": {
            "1": "Create a new trail and configure it to send CloudTrail logs to Amazon S3. Use Amazon EventBridge to send notification if a trail is deleted or stopped.",
            "2": "Deploy an AWS Lambda function in every account to check if there is an existing trail and create a new trail, if needed.",
            "3": "Edit the existing trail in the Organizations management account and apply it to the organization.",
            "4": "Create an SCP to deny the cloudtrail:Delete* and cloudtrail:Stop* actions. Apply the SCP to all accounts."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "130",
        "question": "A company recently had a security audit in which the auditors identified multiple potential threats. These potential threats can cause usage pattern changes such as DNS access peak, abnormal instance traffic, abnormal network interface traffic, and unusual Amazon S3 API calls. The threats can come from different sources and can occur at any time. The company needs to implement a solution to continuously monitor its system and identify all these incoming threats in near-real time. Which solution will meet these requirements?",
        "options": {
            "1": "Enable AWS CloudTrail logs, VPC flow logs, and DNS logs. Use Amazon CloudWatch Logs to manage these logs from a centralized account.",
            "2": "Enable AWS CloudTrail logs, VPC flow logs, and DNS logs. Use Amazon Macie to monitor these logs from a centralized account.",
            "3": "Enable Amazon GuardDuty from a centralized account. Use GuardDuty to manage AWS CloudTrail logs, VPC flow logs, and DNS logs.",
            "4": "Enable Amazon Inspector from a centralized account. Use Amazon Inspector to manage AWS CloudTrail logs, VPC flow logs, and DNS logs."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "131",
        "question": "A company that uses AWS Organizations is using AWS IAM Identity Center (AWS Single Sign-On) to administer access to AWS accounts. A security engineer is creating a custom permission set in IAM Identity Center. The company will use the permission set across multiple accounts. An AWS managed policy and a customer managed policy are attached to the permission set. The security engineer has full administrative permissions and is operating in the management account. When the security engineer attempts to assign the permission set to an IAM Identity Center user who has access to multiple accounts, the assignment fails. What should the security engineer do to resolve this failure?",
        "options": {
            "1": "Create the customer managed policy in every account where the permission set is assigned. Give the customer managed policy the same name and same permissions in each account.",
            "2": "Remove either the AWS managed policy or the customer managed policy from the permission set. Create a second permission set that includes the removed policy. Apply the permission sets separately to the user.",
            "3": "Evaluate the logic of the AWS managed policy and the customer managed policy. Resolve any policy conflicts in the permission set before deployment.",
            "4": "Do not add the new permission set to the user. Instead, edit the user's existing permission set to include the AWS managed policy and the customer managed policy."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "132",
        "question": "A company has thousands of AWS Lambda functions. While reviewing the Lambda functions, a security engineer discovers that sensitive information is being stored in environment variables and is viewable as plaintext in the Lambda console. The values of the sensitive information are only a few characters long. What is the MOST cost-effective way to address this security issue?",
        "options": {
            "1": "Set up IAM policies from the Lambda console to hide access to the environment variables.",
            "2": "Use AWS Step Functions to store the environment variables. Access the environment variables at runtime. Use IAM permissions to restrict access to the environment variables to only the Lambda functions that require access.",
            "3": "Store the environment variables in AWS Secrets Manager, and access them at runtime. Use IAM permissions to restrict access to the secrets to only the Lambda functions that require access.",
            "4": "Store the environment variables in AWS Systems Manager Parameter Store as secure string parameters, and access them at runtime. Use IAM permissions to restrict access to the parameters to only the Lambda functions that require access."
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "133",
        "question": "A security engineer is using AWS Organizations and wants to optimize SCPs. The security engineer needs to ensure that the SCPs conform to best practices. Which approach should the security engineer take to meet this requirement?",
        "options": {
            "1": "Use AWS IAM Access Analyzer to analyze the polices. View the findings from policy validation checks.",
            "2": "Review AWS Trusted Advisor checks for all accounts in the organization.",
            "3": "Set up AWS Audit Manager. Run an assessment for all AWS Regions for all accounts.",
            "4": "Ensure that Amazon Inspector agents are installed on all Amazon EC2 instances in all accounts."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "134",
        "question": "A company has recently recovered from a security incident that required the restoration of Amazon EC2 instances from snapshots. The company uses an AWS Key Management Service (AWS KMS) customer managed key to encrypt all Amazon Elastic Block Store (Amazon EBS) snapshots. The company performs a gap analysis of its disaster recovery procedures and backup strategies. A security engineer needs to implement a solution so that the company can recover the EC2 instances if the AWS account is compromised and the EBS snapshots are deleted. Which solution will meet this requirement?",
        "options": {
            "1": "Create a new Amazon S3 bucket. Use EBS lifecycle policies to move EBS snapshots to the new S3 bucket. Use lifecycle policies to move snapshots to the S3 Glacier Instant Retrieval storage class. Use S3 Object Lock to prevent deletion of the snapshots.",
            "2": "Use AWS Systems Manager to distribute a configuration that backs up all attached disks to Amazon S3.",
            "3": "Create a new AWS account that has limited privileges. Allow the new account to access the KMS key that encrypts the EBS snapshots. Copy the encrypted snapshots to the new account on a recurring basis.",
            "4": "Use AWS Backup to copy EBS snapshots to Amazon S3. Use S3 Object Lock to prevent deletion of the snapshots."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "135",
        "question": "A company's security engineer is designing an isolation procedure for Amazon EC2 instances as part of an incident response plan. The security engineer needs to isolate a target instance to block any traffic to and from the target instance, except for traffic from the company's forensics team. Each of the company's EC2 instances has its own dedicated security group. The EC2 instances are deployed in subnets of a VPC. A subnet can contain multiple instances. The security engineer is testing the procedure for EC2 isolation and opens an SSH session to the target instance. The procedure starts to simulate access to the target instance by an attacker. The security engineer removes the existing security group rules and adds security group rules to give the forensics team access to the target instance on port 22. After these changes, the security engineer notices that the SSH connection is still active and usable. When the security engineer runs a ping command to the public IP address of the target instance, the ping command is blocked. What should the security engineer do to isolate the target instance?",
        "options": {
            "1": "Add an inbound rule to the security group to allow traffic from 0.0.0.0/0 for all ports. Add an outbound rule to the security group to allow traffic to 0.0.0.0/0 for all ports. Then immediately delete these rules.",
            "2": "Remove the port 22 security group rule. Attach an instance role policy that allows AWS Systems Manager Session Manager connections so that the forensics team can access the target instance.",
            "3": "Create a network ACL that is associated with the target instance's subnet. Add a rule at the top of the inbound rule set to deny all traffic from 0.0.0.0/0. Add a rule at the top of the outbound rule set to deny all traffic to 0.0.0.0/0.",
            "4": "Create an AWS Systems Manager document that adds a host-level firewall rule to block all inbound traffic and outbound traffic. Run the document on the target instance."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "136",
        "question": "A startup company is using a single AWS account that has resources in a single AWS Region. A security engineer configures an AWS CloudTrail trail in the same Region to deliver log files to an Amazon S3 bucket by using the AWS CLI. Because of expansion, the company adds resources in multiple Regions. The security engineer notices that the logs from the new Regions are not reaching the S3 bucket. What should the security engineer do to fix this issue with the LEAST amount of operational overhead?",
        "options": {
            "1": "Create a new CloudTrail trail. Select the new Regions where the company added resources.",
            "2": "Change the S3 bucket to receive notifications to track all actions from all Regions.",
            "3": "Create a new CloudTrail trail that applies to all Regions.",
            "4": "Change the existing CloudTrail trail so that it applies to all Regions."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "137",
        "question": "A company's public Application Load Balancer (ALB) recently experienced a DDoS attack. To mitigate this issue, the company deployed Amazon CloudFront in front of the ALB so that users would not directly access the Amazon EC2 instances behind the ALB. The company discovers that some traffic is still coming directly into the ALB and is still being handled by the EC2 instances. Which combination of steps should the company take to ensure that the EC2 instances will receive traffic only from CloudFront? (Choose two.)",
        "options": {
            "1": "Configure CloudFront to add a cache key policy to allow a custom HTTP header that CloudFront sends to the ALB.",
            "2": "Configure CloudFront to add a custom HTTP header to requests that CloudFront sends to the ALB.",
            "3": "Configure the ALB to forward only requests that contain the custom HTTP header.",
            "4": "Configure the ALB and CloudFront to use the X-Forwarded-For header to check client IP addresses.",
            "5": "Configure the ALB and CloudFront to use the same X.509 certificate that is generated by AWS Certificate Manager (ACM)."
        },
        "correct_answers": [
            "options.2",
            "options.3"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "138",
        "question": "A security engineer is checking an AWS CloudFormation template for vulnerabilities. The security engineer finds a parameter that has a default value that exposes an application's API key in plaintext. The parameter is referenced several times throughout the template. The security engineer must replace the parameter while maintaining the ability to reference the value in the template. Which solution will meet these requirements in the MOST secure way?",
        "options": {
            "1": "Store the API key value as a SecureString parameter in AWS Systems Manager Parameter Store. In the template, replace all references to the value with {{resolve:ssm:MySSMParameterName:1}}.",
            "2": "Store the API key value in AWS Secrets Manager. In the template, replace all references to the value with {{resolve:secretsmanager:MySecretId:SecretString}}.",
            "3": "Store the API key value in Amazon DynamoDB. In the template, replace all references to the value with {{resolve:dynamodb:MyTableName:MyPrimaryKey}}.",
            "4": "Store the API key value in a new Amazon S3 bucket. In the template, replace all references to the value with {{resolve:s3:MyBucketName:MyObjectName}}."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "139",
        "question": "A company's AWS CloudTrail logs are all centrally stored in an Amazon S3 bucket. The security team controls the company's AWS account. The security team must prevent unauthorized access and tampering of the CloudTrail logs. Which combination of steps should the security team take? (Choose three.)",
        "options": {
            "1": "Configure server-side encryption with AWS KMS managed encryption keys (SSE-KMS).",
            "2": "Compress log files with secure gzip.",
            "3": "Create an Amazon EventBridge rule to notify the security team of any modifications on CloudTrail log files.",
            "4": "Implement least privilege access to the S3 bucket by configuring a bucket policy.",
            "5": "Configure CloudTrail log file integrity validation.",
            "6": "Configure Access Analyzer for S3."
        },
        "correct_answers": [
            "options.1",
            "options.4",
            "options.5"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "140",
        "question": "A company has several petabytes of data. The company must preserve this data for 7 years to comply with regulatory requirements. The company's compliance team asks a security officer to develop a strategy that will prevent anyone from changing or deleting the data. Which solution will meet this requirement MOST cost-effectively?",
        "options": {
            "1": "Create an Amazon S3 bucket. Configure the bucket to use S3 Object Lock in compliance mode. Upload the data to the bucket. Create a resource-based bucket policy that meets all the regulatory requirements.",
            "2": "Create an Amazon S3 bucket. Configure the bucket to use S3 Object Lock in governance mode. Upload the data to the bucket. Create a user-based IAM policy that meets all the regulatory requirements.",
            "3": "Create a vault in Amazon S3 Glacier. Create a Vault Lock policy in S3 Glacier that meets all the regulatory requirements. Upload the data to the vault.",
            "4": "Create an Amazon S3 bucket. Upload the data to the bucket. Use a lifecycle rule to transition the data to a vault in S3 Glacier. Create a Vault Lock policy that meets all the regulatory requirements."
        },
        "correct_answers": [
            "options.4"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "141",
        "question": "A company has several workloads running on AWS. Employees are required to authenticate using on-premises ADFS and SSO to access the AWS Management Console. Developers migrated an existing legacy web application to an Amazon EC2 instance. Employees need to access this application from anywhere on the internet, but currently, there is no authentication system built into the application. How should the security engineer implement employee-only access to this system without changing the application?",
        "options": {
            "1": "Place the application behind an Application Load Balancer (ALB). Use Amazon Cognito as authentication for the ALB. Define a SAML-based Amazon Cognito user pool and connect it to ADFS.",
            "2": "Implement AWS IAM Identity Center (AWS Single Sign-On) in the management account and link it to ADFS as an identity provider. Define the EC2 instance as a managed resource, then apply an IAM policy on the resource.",
            "3": "Define an Amazon Cognito identity pool, then install the connector on the Active Directory server. Use the Amazon Cognito SDK on the application instance to authenticate the employees using their Active Directory user names and passwords.",
            "4": "Create an AWS Lambda custom authorizer as the authenticator for a reverse proxy on Amazon EC2. Ensure the security group on Amazon EC2 only allows access from the Lambda function."
        },
        "correct_answers": [
            "options.1"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "142",
        "question": "A company is using AWS to run a long-running analysis process on data that is stored in Amazon S3 buckets. The process runs on a fleet of Amazon EC2 instances that are in an Auto Scaling group. The EC2 instances are deployed in a private subnet of a VPC that does not have internet access. The EC2 instances and the S3 buckets are in the same AWS account. The EC2 instances access the S3 buckets through an S3 gateway endpoint that has the default access policy. Each EC2 instance is associated with an instance profile role that has a policy that explicitly allows the s3:GetObject action and the s3:PutObject action for only the required S3 buckets. The company learns that one or more of the EC2 instances are compromised and are exfiltrating data to an S3 bucket that is outside the company's organization in AWS Organizations. A security engineer must implement a solution to stop this exfiltration of data and to keep the EC2 processing job functional. Which solution will meet these requirements?",
        "options": {
            "1": "Update the policy on the S3 gateway endpoint to allow the S3 actions only if the values of the aws:ResourceOrgID and aws:PrincipalOrgID condition keys match the company's values.",
            "2": "Update the policy on the instance profile role to allow the S3 actions only if the value of the aws:ResourceOrgID condition key matches the company's value.",
            "3": "Add a network ACL rule to the subnet of the EC2 instances to block outgoing connections on port 443.",
            "4": "Apply an SCP on the AWS account to allow the S3 actions only if the values of the aws:ResourceOrgID and aws:PrincipalOrgID condition keys match the company's values."
        },
        "correct_answers": [
            "options.2"
        ],
        "description": "",
        "source_url": ""
    },
    {
        "id": "143",
        "question": "A company that operates in a hybrid cloud environment must meet strict compliance requirements. The company wants to create a report that includes evidence from on-premises workloads alongside evidence from AWS resources. A security engineer must implement a solution to collect, review, and manage the evidence to demonstrate compliance with company policy. Which solution will meet these requirements?",
        "options": {
            "1": "Create an assessment in AWS Audit Manager from a prebuilt framework or a custom framework. Upload manual evidence from the on-premises workloads. Add the evidence to the assessment. Generate an assessment report after Audit Manager collects the necessary evidence from the AWS resources.",
            "2": "Install the Amazon CloudWatch agent on the on-premises workloads. Use AWS Config to deploy a conformance pack from a sample conformance pack template or a custom YAML template. Generate an assessment report after AWS Config identifies noncompliant workloads and resources.",
            "3": "Set up the appropriate security standard in AWS Security Hub. Upload manual evidence from the on-premises workloads. Wait for Security Hub to collect the evidence from the AWS resources. Download the list of controls as a .csv file.",
            "4": "Install the Amazon CloudWatch agent on the on-premises workloads. Create a CloudWatch dashboard to monitor the on-premises workloads and the AWS resources. Run a query on the workloads and resources. Download the results."
        },
        "correct_answers": [
            "options.3"
        ],
        "description": "",
        "source_url": ""
    }
]